{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmwJGkws14pd"
      },
      "source": [
        "Assignment 4: Multi-Output Networks and Batch Processing\n",
        "========================================================\n",
        "\n",
        "\n",
        "Microsoft Forms Document: https://forms.office.com/r/nHKeCdSmTz\n",
        "\n",
        "\n",
        "Task 1: Dataset Loading\n",
        "-----------------------\n",
        "\n",
        "Load the dataset from files and provide the input matrix $\\mathbf X \\in \\mathbb R^{(D+1)\\times N}$ and the output matrix $\\mathbf T \\in \\mathbb R^{O\\times N}$.\n",
        "For more information about the dataset, refer to https://archive.ics.uci.edu/ml/datasets/Student+Performance.\n",
        "\n",
        "We skip categorical inputs (indexes 8-11) for now.\n",
        "All other entries are converted either into binary $(-1,1)$ or into an integer range $(0,1,\\ldots)$.\n",
        "The three outputs range between 0 and 20 each."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ozWtvnxU14ph"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy\n",
        "np = numpy\n",
        "import os\n",
        "\n",
        "# Dataset origin: https://archive.ics.uci.edu/ml/datasets/Student+Performance\n",
        "\n",
        "def dataset(course=\"mat\"):\n",
        "  # load dataset and provide input and target data\n",
        "  # possible data files are \"mat\" and \"por\"\n",
        "\n",
        "  # download data file from URL\n",
        "  dataset_zip_file = \"student.zip\"\n",
        "  if not os.path.exists(dataset_zip_file):\n",
        "    import urllib.request\n",
        "    urllib.request.urlretrieve(\"https://archive.ics.uci.edu/ml/machine-learning-databases/00320/student.zip\", dataset_zip_file)\n",
        "    print (\"Downloaded datafile\", dataset_zip_file)\n",
        "\n",
        "  import zipfile\n",
        "  import csv\n",
        "  import io\n",
        "\n",
        "  # collect inputs\n",
        "  inputs = []\n",
        "  targets = []\n",
        "  # some default values: yes=1, no=-1\n",
        "  yn = {\"yes\":1.,\"no\":-1.}\n",
        "  # read through dataset (without actually unzippiung to a file):\n",
        "  # ... open zip file\n",
        "  zip = zipfile.ZipFile(dataset_zip_file)\n",
        "  # ... open data file inside of zip file and convert bytes to text\n",
        "  datafile = io.TextIOWrapper(zip.open(os.path.join(F\"student-{course}.csv\"), 'r'))\n",
        "  # ... read through the lines via CSV reader, using the correct delimited\n",
        "  reader = csv.reader(datafile, delimiter=\";\")\n",
        "  # ... skip header line\n",
        "  next(reader)\n",
        "  for splits in reader:\n",
        "    # read input values\n",
        "    inputs.append([\n",
        "      1.,                             #### BIAS ####\n",
        "      {\"GP\":1.,\"MS\":-1.}[splits[0]],  # school\n",
        "      {\"M\":1.,\"F\":-1.}[splits[1]],    # gender\n",
        "      float(splits[2]),               # age\n",
        "      {\"U\":1.,\"R\":-1.}[splits[3]],    # address\n",
        "      {\"LE3\":1.,\"GT3\":-1.}[splits[4]],# family size\n",
        "      {\"T\":1.,\"A\":-1.}[splits[5]],    # parents living together\n",
        "      float(splits[6]),               # mother education\n",
        "      float(splits[7]),               # father education\n",
        "      # skip categorical values\n",
        "      float(splits[12]),              # travel time\n",
        "      float(splits[13]),              # study time\n",
        "      float(splits[14]),              # failures\n",
        "      yn[splits[15]],                 # extra support\n",
        "      yn[splits[16]],                 # family support\n",
        "      yn[splits[17]],                 # paid support\n",
        "      yn[splits[18]],                 # activities\n",
        "      yn[splits[19]],                 # nursery school\n",
        "      yn[splits[20]],                 # higher education\n",
        "      yn[splits[21]],                 # internet\n",
        "      yn[splits[22]],                 # romantic\n",
        "      float(splits[23]),              # family relation\n",
        "      float(splits[24]),              # free time\n",
        "      float(splits[25]),              # going out\n",
        "      float(splits[26]),              # workday alcohol\n",
        "      float(splits[27]),              # weekend alcohol\n",
        "      float(splits[28]),              # health\n",
        "      float(splits[29]),              # absences\n",
        "    ])\n",
        "\n",
        "    # read targets values\n",
        "    targets.append([\n",
        "      float(splits[30]),              # grade for primary school\n",
        "      float(splits[31]),              # grade for secondary school\n",
        "      float(splits[32]),              # grade for tertiary school\n",
        "    ])\n",
        "\n",
        "  print(F\"Loaded dataset with {len(targets)} samples\")\n",
        "  return np.transpose(np.array(inputs)), np.transpose(np.array(targets))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1J9jIVM14pk"
      },
      "source": [
        "Test 1: Assert Valid Outputs\n",
        "----------------------------\n",
        "\n",
        "Load the dataset and check that all target data are in range 0-20. Also make sure that the dataset is in the correct dimensions, i.e., $\\mathbf X\\in \\mathbb R^{(D+1)\\times N}$ and $\\mathbf T \\in \\mathbb R^{O\\times N}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYxd6dtW14pl",
        "outputId": "546d3342-2a6f-418c-df83-7bb400606bd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloaded datafile student.zip\n",
            "Loaded dataset with 395 samples\n",
            "Dataset Range okay.\n",
            "Shape of X is 27 x 395\n",
            "Shape of T is 3 x 395\n"
          ]
        }
      ],
      "source": [
        "# load dataset\n",
        "# load dataset\n",
        "X, T = dataset(\"mat\")\n",
        "\n",
        "# check validity\n",
        "D=len(X) #27\n",
        "N=len(X[0]) #395\n",
        "O=3\n",
        "\n",
        "assert (np.all(np.array(T)) >= 0) and (np.all(np.array(T)<=20)) \n",
        "print(\"Dataset Range okay.\")\n",
        "\n",
        "assert np.shape(np.array(X))==(D,N)\n",
        "print(\"Shape of X is\", D ,\"x\", N)\n",
        "\n",
        "assert np.shape(np.array(T) )==(O,N)\n",
        "print(\"Shape of T is\", O, \"x\",N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuwVZJzs14pl"
      },
      "source": [
        "Task 2: Input Data Normalization\n",
        "--------------------------------\n",
        "\n",
        "Implement a function that normalizes all input data using the whitening method with given mean and standard deviation.\n",
        "Compute the mean and the standard deviation for your dataset.\n",
        "Make sure that you handle the bias neuron $x_0$ correctly.\n",
        "Finally, normalize your input data using the implemented function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fgXbivuK14pm"
      },
      "outputs": [],
      "source": [
        "# compute mean and standard deviation over dataset\n",
        "# compute mean and standard deviation over dataset\n",
        "mean = np.mean(X, axis=1) #average for each row\n",
        "std = np.std(X, axis=1)\n",
        "\n",
        "# assure to handle x_0 correctly\n",
        "mean[0]=0\n",
        "std[0]=1 #avoid division by 0\n",
        "\n",
        "def normalize(x, mean, std):\n",
        "  # standardize the given data with the given meand and standard deviation\n",
        "  return ((x.T-mean)/std).T\n",
        "\n",
        "# normalize our dataset\n",
        "X = normalize(X, mean, std)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8xtpcod14pm"
      },
      "source": [
        "Task 3: Batch Processing\n",
        "------------------------\n",
        "\n",
        "Implement a function that turns the dataset $(X,T)$ into batches of a certain batch size $B$.\n",
        "Implement this function as a generator function, i.e., use ``yield`` instead of ``return``.\n",
        "Make sure that you yield both the input batch as well as the target batch.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Tmgq3TIx14pn"
      },
      "outputs": [],
      "source": [
        "def batch(X, T, batch_size=16):\n",
        "  shuffle = np.random.permutation(T.shape[1])\n",
        "  idx = 0\n",
        "  while True:\n",
        "    # shuffle dataset in each epoch\n",
        "    yield X[:,shuffle[idx:idx + batch_size]], T[:,shuffle[idx:idx + batch_size]]\n",
        "    idx += batch_size\n",
        "    if (idx >= T.shape[1]):\n",
        "      shuffle = np.random.permutation(T.shape[1])\n",
        "      idx = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1fU-1dc14pn"
      },
      "source": [
        "Test 2: Test your Batches\n",
        "-------------------------\n",
        "\n",
        "Make sure that your batch function returns batches in the correct size and with the correct content, i.e., $(\\vec x, \\vec t)$-alignment.\n",
        "Select appropriate test data that makes it easy to test this.\n",
        "\n",
        "Also check that the batches are in the correct dimensions, i.e., that $\\mathbf X \\in \\mathbb R^{(D+1)\\times B}$ and $\\mathbf T \\in \\mathbb R^{O\\times B}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlkKkxRk14po",
        "outputId": "0812883b-b9f3-4fc6-8b1f-d447b7009053"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batches are as expected\n"
          ]
        }
      ],
      "source": [
        "# designe and create test data to test your batch processing function\n",
        "# designe and create test data to test your batch processing function\n",
        "xx = np.arange(0,40,2)\n",
        "XX=np.array([xx,10*xx]) #2x20\n",
        "TT = 2*XX\n",
        "\n",
        "for counter, (x,t) in enumerate(batch(XX, TT, 10)):\n",
        "  # test that the batches are in the desired form and content\n",
        "  assert np.all(t==2*x)\n",
        "\n",
        "  # we run this for a couple of batches, to assure that it works over some epochs\n",
        "  if counter == 20: break\n",
        "\n",
        "print(\"Batches are as expected\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySigRKOG14po"
      },
      "source": [
        "Task 4: Multi-Output Network\n",
        "----------------------------\n",
        "\n",
        "Implement a multi-target network that computes the output matrix $\\mathbf Y$ for a given input dataset/batch $\\mathbf X$ and given parameters $\\Theta=(\\mathbf W^{(1)}, \\mathbf W^{(2)})$. \n",
        "The function should return both the output of the hidden units $\\mathbf H$ as well as the network output $\\mathbf Y$. Select $\\tanh$ as the activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9hiHDo3u14po"
      },
      "outputs": [],
      "source": [
        "def network(X, Theta):\n",
        "  W1, W2 = Theta\n",
        "\n",
        "  # compute activation\n",
        "  A = np.matmul(W1, X)\n",
        "\n",
        "  # compute hidden unit output\n",
        "  H = (np.exp(A) - np.exp(-A)) / (np.exp(A) + np.exp(-A))\n",
        "  H[0] = 1\n",
        "\n",
        "  # compute network output\n",
        "  Y = np.dot(W2, H)\n",
        "\n",
        "  return Y, H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMgdmHwI14pp"
      },
      "source": [
        "Task 5: Loss Implementation\n",
        "---------------------------\n",
        "\n",
        "Implement a function that computes the loss $\\mathcal J^{L_2}_\\Theta$ for a given network output $\\mathbf Y$, and their according targets $\\mathbf T$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PNe7C15L14pp"
      },
      "outputs": [],
      "source": [
        "def loss(Y, T):\n",
        "  N=len(Y[0])\n",
        "  return 1/N*np.linalg.norm(Y-T, \"fro\")**2 #Frobenius norm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D45KJuaM14pp"
      },
      "source": [
        "Task 6: Gradient Implementation\n",
        "-------------------------------\n",
        "\n",
        "Implement a function that computes the gradient $\\nabla_\\Theta\\mathcal J^{L_2}$ for both weight matrices $\\Theta=(\\mathbf W^{(1)}, \\mathbf W^{(2)})$.\n",
        "Assume that the function gets the network input, $\\mathbf X$, its output $\\mathbf Y$, hidden unit activations $\\mathbf H$ and target values $\\mathbf T$.\n",
        "Remember that we have used $\\tanh$ as the activation function and change the implementation seen in the lecture accordingly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "biWML8rU14pq"
      },
      "outputs": [],
      "source": [
        "def gradient(X, T, Y, H, Theta):\n",
        "  W1, W2 = Theta\n",
        "\n",
        "  # first layer gradient\n",
        "  g1 = (2/np.shape(Y)[1])*np.dot((np.dot(W2.T,(Y-T))*(1-H**2)),X.T)\n",
        "  # second layer gradient\n",
        "  g2 = (2/np.shape(Y)[1])*(np.dot((Y-T),H.T))\n",
        " \n",
        "  return g1, g2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXJmvQ7M14pq"
      },
      "source": [
        "Task 7: Iterative Gradient Descent\n",
        "----------------------------------\n",
        "Implement the iterative gradient descent using the normalized dataset from Task 2, split into batches with the function from Task 3, the network from Task 4, the loss from Task 5 and the gradient from Task 6.\n",
        "Make sure that the network output $\\mathbf Y$ and the hidden unit output $\\mathbf H$ is computed only once for each batch.\n",
        "Store the loss values for each batch in a list and return it at the end.\n",
        "Use the number of epochs to be 10000, the batch size $B$, and the learning rate $\\eta=0.001$.\n",
        "How many iterations do we need when $B<N$?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZsF68SLD14pq"
      },
      "outputs": [],
      "source": [
        "def gradient_descent(X, T, Theta, B, eta=0.001):\n",
        "  loss_values = []\n",
        "  (W1, W2) = Theta\n",
        "  max_epochs = 10000\n",
        "  epoch = 0\n",
        "  data_num = 0\n",
        "  x_ticks = []\n",
        "  # iterate over batches\n",
        "  gen = batch(X, T, batch_size=B)\n",
        "  for c, (x, t) in enumerate(gen):\n",
        "    # compute network output\n",
        "    (y, h) = network(x, (W1, W2))\n",
        "\n",
        "    # compute gradient\n",
        "    (g1, g2) = gradient(x, t, y, h, (W1, W2))\n",
        "\n",
        "    # compute and append loss\n",
        "    l = loss(y, t)\n",
        "\n",
        "    # and apply gradient descent\n",
        "    W1 -= eta * g1 \n",
        "    W2 -= eta * g2 \n",
        "\n",
        "    data_num += B\n",
        "    if data_num > len(T[0]):\n",
        "      epoch += 1\n",
        "      data_num = 0\n",
        "      loss_values.append(l)\n",
        "      if (epoch >= max_epochs):\n",
        "        break\n",
        "\n",
        "  # return the obtained loss values at the end\n",
        "  return loss_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyXyAe8I14pq"
      },
      "source": [
        "Task 8: Run Gradient Descent\n",
        "----------------------------\n",
        "\n",
        "Select an appropriate number of hidden neurons $K$.\n",
        "Instantiate the weight matrices using the Xavier method as introduced in the lecture.\n",
        "Run the gradient descent twice, once as stochastic gradient descent with batch size $B=16$ and once as normal gradient descent.\n",
        "How can you achieve this without providing a different implementation for the ``gradient_descent`` function?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-bvOiCq414pq"
      },
      "outputs": [],
      "source": [
        "K = 20\n",
        "D = len(X)\n",
        "O = 3\n",
        "W1 = np.random.uniform(-1/np.sqrt(D), 1/np.sqrt(D), (K,D)) ######W0=0??\n",
        "W2 = np.random.uniform(-1/np.sqrt(D), 1/np.sqrt(D), (O,K))\n",
        "Theta = [W1, W2]\n",
        "\n",
        "import copy\n",
        "\n",
        "# run gradient descent with full dataset\n",
        "Theta1 = copy.deepcopy(Theta)\n",
        "GD = gradient_descent(X, T, Theta1, len(X[0]), eta=0.001)\n",
        "\n",
        "# run stochastic gradient descent with batches of size 16\n",
        "Theta2 = copy.deepcopy(Theta)\n",
        "SGD = gradient_descent(X, T, Theta2, 16, eta=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvHpEup814pr"
      },
      "source": [
        "Task 9: Plotting Loss Progression\n",
        "---------------------------------\n",
        "\n",
        "Plot the progression of the two gradient descent steps together into one plot.\n",
        "Do we need to take care of something when plotting both together?\n",
        "Choose logarithmic axes whenever you see fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "oKxY0oMz14pr",
        "outputId": "7aefa7fa-fc95-45bd-f350-cdd4083f20b7"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABGpklEQVR4nO3dd3hURffA8e+kERI6Aem9SAkJEKT3/iKIgqKiAq+KKALiq+LPAopgx0IRBEVQqaKCIAKCNCEqVXqvUVroPQHm98dws5tkN9lNNtlNcj7Pkye7d++9e3LFs7Mzc88orTVCCCGyFz9vByCEEMLzJLkLIUQ2JMldCCGyIUnuQgiRDUlyF0KIbEiSuxBCZEMB3g4AICwsTJcrV87bYQghRJayYcOGWK11EUev+URyL1euHOvXr/d2GEIIkaUopQ47e82r3TJKqc5KqYnnz5/3ZhhCCJHteDW5a63na6375s+f35thCCFEtiMDqkIIkQ35RJ+7EBklPj6emJgYrl275u1QhEiz4OBgSpUqRWBgoMvHSHIX2VpMTAx58+alXLlyKKW8HY4QbtNac/r0aWJiYihfvrzLx0m3jMjWrl27RuHChSWxiyxLKUXhwoXd/vbp1Za7Uqoz0LlCxQpcvH4xzefx9/PHX/nj7+ePn/LDT8lnlrCRxC6yurT8G/ZqctdazwfmqxLqyXzv5vPoua1k78pvP+Xn8LUAvwCC/IOc//g5fy3QPzDFY4MDggkJDCE0MJTQoNCEx8EBwZKMspmRI0cyffp0/P398fPz4/PPP6d+/fp88skn9O3bl5CQELfP+cYbb5AnTx5eeOGFdMU2ZcoU2rVrR4kSJQB44okneP7556levbpLx//111+89NJL/PPPP+TNm5fixYvz7rvvEh4enuaYWrRowYcffkhUVBT/+c9/mD59OgUKFHD7PHPnzqVKlSoO/5Y33niDSZMmUaRIES5fvkx4eDgjRoxw+e/OCCtWrCAoKIhGjRp55Hw+0edeKl8pnmv7XJqO1Whu3rrJTX2TW/pWwmOXf6dwXPyteOJvxnP9xnUuxV0i7mZcqj/ppVAm0QeFEhoYmuhxaFAo+XPlp0BwgWQ/9tsLhxSmQHAB+QbjA6Kjo1mwYAEbN24kV65cxMbGEhdn/p188sknPPLII2lK7p4yZcoUatasmZDcv/jiC5ePPXHiBA888ADTp09PSEi///47+/fvT5bcb9y4QUCA++lm4cKFbh9jmTt3LnfffbfThD148OCED8dZs2bRqlUrtm7dSpEiDm/4zHArVqwgT5482Su535HnDv7X6H/eDiPdtNbcuHXDaeKPvxWf8Phq/FWuxF/hcvxlLsddTnh8Jf4Kl+Mu2x7bbfvnwj/suL6Dc9fOce7aOW7pW05jCfALoEhIEYqGFk30c0foHZTOX5rS+UpTOn9pSuYtSaC/6yPwwj3Hjh0jLCyMXLlyARAWFgbA6NGj+ffff2nZsiVhYWEsX76cGTNm8Pbbb6O1plOnTrz33nsALFq0iFdeeYWbN28SFhbGsmXLANixYwctWrTgyJEjPPfccwwcOBCArl27cvToUa5du8agQYPo27cvN2/e5PHHH2f9+vUopfjvf/9L6dKlWb9+PT179iR37txER0fTsWPHhFazs/e1jB07ll69eiVKRk2aNEl43Lt3bwoVKsSmTZuoU6cOPXr04LnnnuPq1avkzp2br776iqpVq3L16lX69OnDjh07qFatGlevXk04h3X3elhYGN9++y2jR48mLi6O+vXr89lnn+Hv70+ePHkYNGgQCxYsIHfu3MybN4/9+/fz008/sXLlSkaMGMH3339PxYoVnf536tGjBz///DPTp09n0KBBbNiwgeeff55Lly4RFhbGlClTKF68OKNHj2bChAkEBARQvXp1Zs6cyaVLlxgwYEDCtR02bBjdunVjyZIlDBs2jOvXr1OxYkW++uor8uTJQ7ly5ejVqxfz588nPj6e7777juDgYCZMmIC/vz/ffvstY8aMoWnTpun5p+cbyT27UEoR6B9IoH8goYRm6HtprbkUd4nz188nJPtz185x9upZTl89zcnLJxP97Duzj5OXT3I5/nLimFEUz1ucsvnLUrlwZaoUqkKVwuancuHKhAR6r1Xpac89B5s3e/ackZHwySfOX2/Xrh3Dhw+nSpUqtGnThh49etC8eXMGDhzIRx99xPLlywkLC+Pff/9lyJAhbNiwgYIFC9KuXTvmzp1L48aNefLJJ1m1ahXly5fnzJkzCefetWsXy5cv5+LFi1StWpWnn36awMBAJk+eTKFChbh69Sr16tWjW7duHDp0iH/++Ydt27YBcO7cOQoUKMDYsWMTkrm9U6dOOX1fy/bt2+nVq1eK12fPnj0sXboUf39/Lly4wKpVqwgICGDp0qW88sorfP/994wfP56QkBC2bNnCli1bqFOnTrLz7Ny5k1mzZrFmzRoCAwN55plnmDZtGo899hiXL1+mQYMGjBw5kpdeeolJkybx2muv0aVLF+6++266d++eYoyWOnXqsGvXLuLj4xkwYADz5s2jSJEizJo1i1dffZXJkyfz7rvvcvDgQXLlysW5c+cAeOutt8ifPz9bt24F4OzZs8TGxjJixAiWLl1KaGgo7733Hh999BFDhw4FzIf8xo0b+eyzz/jwww/54osv6Nevn0e62iyS3LMopRR5c+Ulb668lMpXyuXjLsVd4uj5oxy9cJQj548kPD507hDLDizj67+/tr0HisqFK1O7WG0ii0VSu1ht6pWsR6HchTLiT8qW8uTJw4YNG1i9ejXLly+nR48evPvuu/Tu3TvRfuvWraNFixYJXQI9e/Zk1apV+Pv706xZs4QpcIUK2a59p06dyJUrF7ly5aJo0aKcOHGCUqVKMXr0aH788UcAjh49yt69e6latSoHDhxgwIABdOrUiXbt2qUY9x9//OH0fZ2pX78+Fy5coF27dnz66acA3H///fj7+wNw/vx5evXqxd69e1FKER8fD8CqVasSvnXUqlWLWrVqJTv3smXL2LBhA/Xq1QPg6tWrFC1aFICgoCDuvvtuAOrWrcuvv/6aaqyOWOtJ7969m23bttG2bVsAbt68SfHixRPi69mzJ127dqVr164ALF26lJkzZyacp2DBgixYsIAdO3bQuHFjAOLi4mjYsGHCPvfdd19CvD/88EOa4k2NJPccJk9QHqoVqUa1ItUcvn4p7hL7zuxjz+k97Dy1k80nNvNHzB/M2j4rYZ/wouE0K9uMZmWb0bp8awqHFM6s8NMlpRZ2RvL396dFixa0aNGC8PBwpk6dmiy5O1uoXmvtdIDd6uqx3uPGjRusWLGCpUuXEh0dTUhICC1atODatWsULFiQv//+m8WLFzNu3Dhmz57N5MmTncac0vtaatSowcaNG7nnnnsA+PPPP5kzZw4LFixI2Cc01PYN9vXXX6dly5b8+OOPHDp0iBYtWiS8ltp7aa3p1asX77zzTrLXAgMDE463rkNabNq0iaioKLTW1KhRg+jo6GT7/Pzzz6xatYqffvqJt956i+3btzu8Vlpr2rZty4wZMxy+l/XfLj3xpsYnkvuFC7B0adqOrVgR3JjXL1KRJygPkcUiiSwWmWj7matn2Hx8M2uPrmXV4VVM2TyFcevG4af8aFy6MZ2rdKbrnV2pXLiydwL3Ubt378bPz4/Klc112bx5M2XLlgUgb968XLx4kbCwMOrXr8+gQYOIjY2lYMGCzJgxgwEDBtCwYUP69+/PwYMHE7pHUmpFnz9/noIFCxISEsKuXbv4448/AIiNjSUoKIhu3bpRsWLFhA8XK4akXHnf/v37U79+fdq3b5/Q737lypUUYytZsiRgBnItzZo1Y9q0abRs2ZJt27axZcuWZMe2bt2ae+65h8GDB1O0aFHOnDnDxYsXE66lI87+Nke+//57lixZwqhRo8ifPz+nTp0iOjqahg0bEh8fz549e6hWrRpHjx6lZcuWNGnShOnTp3Pp0iXatWvH2LFj+eR26+Hs2bM0aNCA/v37s2/fPipVqsSVK1eIiYmhSpUqKcZ74cIFl+J1idbaaz9AZ2Ai1NWg0/QTFKT1zp1aZLK4G3E6+mi0fv2313XkhEjNG2jeQDf4ooGesG6CPnv1rLdD1FprvWPHDq++//r163XDhg11tWrVdHh4uL733nv1qVOntNZajx49WletWlW3aNFCa631tGnTdM2aNXWNGjX0iy++mHCOhQsX6sjISF2rVi3dpk0brbXWw4YN0x988EHCPjVq1NAHDx7U165d0x06dNDh4eG6e/fuunnz5nr58uV68+bNunbt2joiIkJHRETohQsXaq21njNnjq5SpYqOiIjQV65c0c2bN9fr1q1z+r5JRUdH62bNmumKFSvqhg0b6s6dOycc36tXL/3dd98l7Lt27VpduXJl3ahRI/3aa6/psmXLaq21vnLliu7Ro4cODw/Xjz76qG7YsGHCOcqWLZtwvWbOnKkjIiJ0eHi4rlOnjo6OjtZaax0aGprwHt99953u1auX1lrr33//XVerVk1HRkbqffv2JYp72LBhukSJEjoiIkJXqlRJd+3aVW/fvj3h9U2bNummTZvqWrVq6erVq+uJEyfquLg43bhx44T/Ru+8847WWuuLFy/qxx57TNeoUUPXqlVLf//991prrZctW6ajoqJ0eHi4Dg8P1/PmzUv2N61bt043b95ca6317t27dXh4uI6IiNCrVq1Kdq0d/VsG1msn+VVpJ18HM9Odd0bpL75wv5779evQrRvcdRcsXgwyPdx7jpw/wuzts5myeQrbT20nOCCY/0b+l/81+h8VClbwWlw7d+6kWjXHXVBCZCWO/i0rpTZoraMc7e8TyT0qKkqndbGO0aNh0CD44Qe4914PBybcprVmw7ENjF83nm+2fMNNfZMeNXowotUIryR5Se4iu3A3uWf5u1yeeQZq1oTBgyGF7j6RSZRSRJWI4st7vuTQc4f4X8P/MW/3PKqNq8aLS17k3LVz3g5RiBwhyyf3gAAYOxYOH4bb93wIH1Eibwneb/s+ewfspWd4T0ZFj6LGZzVYtG+Rt0MTItvL8skdoHlzeOghk9wPHPB2NCKpEnlLMPmeyfz15F8UDC5Ix2kd6Tu/L1fi5auWEBklWyR3gA8+MK34wYO9HYlwJqpEFBv6bmBI4yF8sfELmkxuwuFzTtf3FUKkQ7ZJ7iVLwtCh8NNPkI5aQyKD5QrIxbtt3mX+Q/M5cPYAdSfWZc2RNd4OS4hsJ9skdzC1Q6pUMbNnrl/3djQiJZ2qdOKvJ/+iUO5CtPu2HUv2L/F2SBnmxIkTPPzww1SoUIG6devSsGHDhPIAafXGG2/w4YcfAjB06FCWpvEuwM2bNzutvLhixQry589P7dq1qVq1Ks2aNUt096k3HDp0iOnTp3s1hqwiWyX3oCAzNXLfPvjoI29HI1JTpXAVVvdZTeVClek8ozM/7f7J2yF5nNaarl270qxZMw4cOMCGDRuYOXMmMTExyfZN623ow4cPp02bNmk6NqXkDtC0aVM2bdrE7t27GT16NM8++2yy6pCZSZK767JVcgdo3x66doURI+DoUW9HI1JzR547WN5rORF3RPDAdw+w8tBKb4fkUb/99htBQUH069cvYVvZsmUZMGAAYG7Dv//+++ncuTPt2rXj0qVLtG7dmjp16hAeHs68efMSjhs5ciRVq1alTZs27N69O2F77969mTNnDgAbNmygefPm1K1bl/bt23Ps2DHALIAxZMgQ7rrrLqpUqcLq1auJi4tj6NChzJo1i8jISGbNstUPciQyMpKhQ4cyduxYwFSO7NatG/Xq1aNevXqsWWO611auXElkZCSRkZHUrl07oQTA+++/T3h4OBEREbz88ssA7N+/nw4dOlC3bl2aNm3Krl27Ev6mgQMH0qhRIypUqJDw97388susXr2ayMhIPv744zT+V8kZfGKZvUqVKnn0vB99BNWrwwsvQCr/XoUPKJi7IL/0/IWmXzWly8wurOy9MlltG094btFzbD6+2aPnjCwWyScdPnH6+vbt2x2WsLUXHR3Nli1bKFSoEDdu3ODHH38kX758xMbG0qBBA7p06cLGjRuZOXMmmzZt4saNG9SpU4e6desmOk9KpWrBfDP466+/WLhwIW+++SZLly5l+PDhrF+/PiFhp6ZOnTp88MEHAAwaNIjBgwfTpEkTjhw5Qvv27dm5cycffvgh48aNo3Hjxly6dIng4GB++eUX5s6dy59//klISEhCCeG+ffsyYcIEKleuzJ9//skzzzzDb7/9Bpha+L///ju7du2iS5cudO/enXfffZcPP/zQ691DWYFPLLMXFRX1pCfPW748vPwyvPEG9OsHLVt68uwiIxQOKcziRxbTaHIjuszowvq+6ykaWtTbYXlc//79+f333wkKCmLdunUAtG3bNqEol9aaV155hVWrVuHn58c///zDiRMnWL16Nffee2/Cqk1dunRJdu6UStVC4jKzhw4dSlP89ne0L126lB07diQ8v3DhAhcvXqRx48Y8//zz9OzZk/vuu49SpUqxdOlS+vTpkxB/oUKFuHTpEmvXruX+++9POMd1u8Gyrl274ufnR/Xq1Tlx4kSa4s3JfKIqZEZ46SWYMgUGDIBNmyBQFhvyeaXzl2Zuj7k0+aoJD3z3AL8++qtHV4lKqYWdUWrUqMH333+f8HzcuHHExsYmWhzDvizutGnTOHXqFBs2bCAwMJBy5colrHrvSllcZ6VqwTNlZjdt2pRwC/ytW7eIjo4md+7cifZ5+eWX6dSpEwsXLqRBgwYsXbrUYVncW7duUaBAATY7WUHFvqSxL5RJyWqyXZ+7JXduU797+3YYN87b0QhX1S1Rly+7fMnKwyt5Zdkr3g4n3Vq1asW1a9cYP358wrbUyuIWLVqUwMBAli9fzuHD5j6AZs2a8eOPP3L16lUuXrzI/Pnzkx1btWrVhFK1YLpptm/fnmJ87pTF3bJlC2+99Rb9+/cHSCh1a7GStLWG6pAhQ4iKimLXrl20a9eOyZMnJ/ztZ86cIV++fJQvX57vvvsOMAn877//9li8OV22Te4AXbpAhw4wbBgcP+7taISrHg5/mKejnubD6A9ZeiCNhf59hFKKuXPnsnLlSsqXL89dd91Fr169EtZHTapnz56sX7+eqKgopk2bxp133gmQsAZpZGQk3bp1c7i+ZlBQEHPmzGHIkCFEREQQGRnJ2rVrU4yvZcuW7Nixw+mA6urVqxOmQvbv35/Ro0fTunVrwKwDu379emrVqkX16tWZMGECYBb+rlmzJhEREeTOnZuOHTvSoUMHunTpQlRUFJGRkQnTOKdNm8aXX35JREQENWrUSDSA7EitWrUICAggIiJCBlRTkeWrQqZmzx5TWOzhh003jcgarsRfod6kepy5eoatT28lLCQsTeeRqpAiu8hxVSFTU6UK/O9/MHUqpNKIET4kJDCE6fdNJ/ZKLC8s8cyCwULkJNk+uQO8+qopT/Dss3DzprejEa6KKBbBkMZDmPr31CzfPSNEZssRyT1PHhg1ysyamTTJ29EId7zW7DUqF6rMUwuekiqSQrghRyR3gAcegBYtTCv+9GlvRyNcFRwQzMTOEzlw9gDDVw5P0zl8YVxJiPRIy7/hHJPclYIxY+D8eZPgRdbRolwLekf25qPoj9h3Zp9bxwYHB3P69GlJ8CLL0lpz+vRpgoOD3Tou28+WSWrwYPj0U1i3DpLcvS182LGLx6g8pjLtKrbjhx4/uHxcfHw8MTExCTcCCZEVBQcHU6pUKQKT3I2ZrRfIdtf582YGTYUKsGYN+OWY7y5Z38hVI3lt+Wss77WcFuVaeDscIbwuR0+FTCp/fnj/ffjjD/j6a29HI9zxfMPnKZO/DIMXD+aWvuXtcITwaTkuuQM8+ig0bAhDhsC5c96ORrgqd2Bu3mn9DpuPb2bWNin3KURKMiS5K6W6KqUmKaXmKaXaZcR7pIefH4wdC6dOmcqRIut4sOaDhBcNZ+iKocTfjPd2OEL4LJeTu1JqslLqpFJqW5LtHZRSu5VS+5RSLwNoredqrZ8EegM9PBqxh9SpA089ZZL81q3ejka4yk/5MaLVCPad2cfUv6d6OxwhfJY7LfcpQAf7DUopf2Ac0BGoDjyklKput8trt1/3SSNGmD74AQPAB8aVhYs6V+nMXSXvYvjK4Vy/IYvlCuGIy8lda70KOJNk813APq31Aa11HDATuEcZ7wG/aK03ei5czypcGEaOhJUrZcWmrEQpxchWIzl64Sifb/jc2+EI4ZPS2+deErBfqTTm9rYBQBugu1Kqn6MDlVJ9lVLrlVLrT506lc4w0u7JJ6F2bVNc7NIlr4Uh3NS6fGtalmvJyNUjuRx32dvhCOFz0pvcHS0No7XWo7XWdbXW/bTWExwdqLWeqLWO0lpHFSlSJJ1hpJ2/v+l3//df000jsgalFCNajeDk5ZOMW+ezPX9CeE16k3sMUNrueSng33SeM9M1agS9epmFtffs8XY0wlWNSjeiQ6UOvL/mfS5el9V5hLCX3uS+DqislCqvlAoCHgR+cvVgpVRnpdTE8+fPpzOM9Hv3XbM038CBaR9cPXTILAiSwipqwsOGtxjO6aun+fTPT70dihA+xZ2pkDOAaKCqUipGKfW41voG8CywGNgJzNZap7xoox2t9Xytdd/8+fO7G7fHFSsGb74JixfDTy5/PJkKk+PHQ5MmUL489Olj+vFl9k3mqFeyHl2qdmFU9CjOXTvn7XCE8Bk5rrZMSuLjzeDq5cuwY4dpyTty5QrMnw/ffguLFsGNG1C9OvTsae54/eADk/D7ORxKFp729/G/ifw8ktebvc7wlmkrCyxEVuSztWV8qVsGIDDQlAU+dMjUn7F34wYsWWL65u+4Ax580Cz+8dxz5ve2bfDKK6Z7p2NHGDQIfODzKkeIKBZB9+rd+eSPTzh9RYr1CwHScnfowQdh3jzTeo+NhWnTYOZMOHHC3PTUvbtppTdrZmbbJHX6tLkD1s8PNm6EggUz/2/Iabaf3E74+HBeavwS77Z519vhCJEppOSvm2JioGpV8/jKFQgKgk6dTELv1AlcqZn/55/QtCm0b28+KKS0cMbr+UNP5u6ay4GBB7gjzx3eDkeIDCfdMm4qVcp0zzRtatZcPX4cfvgBunVzLbED1K9v1m1dsMD0wYuMN6z5MK7duMZ7a97zdihCeJ203DOQ1qaL5/vvYdkyaN7c2xFlf33m9WHmtpnsH7ifEnlLeDscITKUz7bcszul4IsvoFIlk+SPH/d2RNnf0GZDuXHrBm+vftvboQjhVZLcM1jevDBnjlne76GHzKwbkXHKFyzPfyP/y8QNEzl49qC3wxHCa6TPPRPUrAkTJsCKFTBsmLejyf6GNh9KkH8Qzy953tuhCOE1Xk3uvnSHakZ77DFz5+rbb8PPP7t//Pbt0LatmZZ5y43lQ+PizHz7zz4zd88+9JC5WSs7K5mvJK83e525u+ayaN8ib4cjhFfIgGomunbNrN16+LC58alsWdeOu3nTHLdunXlet66ZgdOyZcrHXb8O9erZVpoKDjYx7NkDlSun/e/ICq7fuE6tCbXQWrP16a3kCsjl7ZCE8DgZUPURwcGm//3WLeja1fXFuceMMYn922/hm2/M2q+tWkHnzuZGK2fGjTOJffRoc9ft/Plm+7Fjifc7cQI+/DB7jQfkCsjF6A6j2XtmrwyuipxJa+31n7p16+qcZNEirQMDtW7QQOsLF1Le99AhrUNDte7YUetbt8y2K1e0fvddrfPl09rfX+vp05Mfd/q01gULat2+vW3btm1ag9YzZybed8wYs3327PT9Xb7osR8f0/5v+uu/Yv7ydihCeBywXjvJqzKg6gXt28Ps2aY1fvfdzksEaw1PP20ejx9vplaCKWg2ZAjs3w+NG5t6N8uXJz525EgzQ8f+BqpixczvpC136/nHH7v/t5w+bW72OuiDE1OuXYOYSZ9SJLgEj/z4CBeuX/B2SEJkGhlQ9ZKuXc3g6O+/wz33mESU1MyZ8MsvZoUoR/3zYWEwd67pP7/3XlO8DODAAbO6VO/eEB5u279QIVNKIWlyt+bfR0ebsgnuWLfO/A3R0e4dl15awx9/pLzPX3/BbwsLUGT1N+w/s5/HfnyMW9qN0WghsjDpc/eiHj1g8mRYutQUI4uLs712+rSpLFmvHgwY4PwcBQuaD4CQEFON8p9/THXKgAAYnqT6rVKm9e6o5V6liimK5m7r/ejtFXRjY907Lr1WrzaDzM7G4a9ft31gFjjfnFHtRjFv9zyG/DoE7eIkAqsSqBBZkSR3L+vVy8yB//lnePhh26DmCy/AmTOmto2jypP2ypSBhQvNAG2zZjBrljm+ZMnk+xYvnvxO2ePHTev/iSfMgO+RI67H763kfuKE+f3PP+b3pk3mW4n1vEIF0/1lGVh/IM9EPcOH0R/yxoo3XErwI0aYcyxd6uHghcgEktx9wFNPwSefmBo0vXrBr7+a5fpeegkiIlw7R2SkOf7IEVNv/sUXHe9XvLjjlnuxYuYbgtamS8dV1geBp5J769bm20xqLtzuPj9zxvweO9bM31+82Dz/124lX6XMgtpj/jOGPpF9GL5qOE8teIq4m3GkZO9e89v6IBEiK5Hk7iMGDTILfUyfbsoKV6oEr7/u3jnatYPffjOt+Dx5HO+TNLnfvAknT5rkXrasOYc7N1klbbn/+y9cTONa1bdumfgffzz1fa3kfvr22hzWN56AgOT7WgPR07714+0GX/BKk1eYtHESd026iy0ntjh9Dx+4BUSINJPZMj5kyBB44w2TjCZOdL7MX0qaNjULhThTvLhJiFb/fmysSarFi5vntWubm5ziUm7UJkia3Fu0gFdfdT9ucH1h8UaN4PnblQWslntqyf3wYXOXcNd7/Ng0aiQTW87j2KVj1Pm8Dk/89AT7zuxj+HDbBwHYkrv9NiGyCpkt42OGDYOzZ1O/+zStrCRu9btbrXhrmmTNmiZR7tmT+rm0tiX3U6fMcfv3m1IJ9vu4+kFx6ZLt8c2btsfbt5sFTyz2M3OSJndH4xNKmWsKZjbQL7/Ais+7sP2Z7Tx717N8s+UbKo+pzLCDzeGuMfyxfydaa2bOtB3vqoMHzWCuEN4m3TI+KCQk485tJXcrqVtJ3tpes6b5bU2rTElsrJmRopR5fPKk+RZw+LBtny++gNKlXUt4ly/bHtvPm69Z00wddcSVljuYOf/2tIawkDA+6fAJBwcd5O1WbxNQ4AT8ZyANv61OkQ+KQK9W0GEQi8+OYd6ueWw6tonYK7FOB2MvXTIDua50KwmR0Zz8ryCyq6TJPWnLvWpV0/q1b307Y7Xaq1QxLXZrpsqRI6bl7e8Pa9aYpL9vH9SokfL57FvuO3aYcQd7V68m7wd31HJPOt6glK1v3pESeUvwf03/j7kv/B9/7TlIvw+WEl9kHV/u3QJ1vmDqqStMnWXbP8AvgLCQMMJCwigSUiThd27C4K4i/LS/CMsPFqVoqPkplLsQ/n6pTHkSwsMkuecwSe9StVru1vZcucy0SFda7lZyr1MHdu+GXbvM8/h4c/5SpWDnTrNt167kyV1reO89eOAB0+K1b7nv3AlduiTe/9ix5BUtkyb3GzcSnwds3yxSExgInCtP05An6dr2Sb7sCqAZ//Upolof4ej5oxw5f4QTl08QeyWWU1dOceryKbac2MKpK6c4c/UM/AcuAq2+tp3XT/lROHfhhGRfNLQoRUKKJDwula8UZfKXoUz+MuQPli5K4RmS3HOYokVNsrNvuefLl7grqGZN2Lw59XNZyb12bZgxA7bYTTw5fNjMs7cSvpXk7R08CP/3f+bn2LHELfdTp5Lvf+xY8kHXpMndWTG2pMl9xgxToqF8+eT73rhh/yGiKBBYlKgSRYkq4bD4ni2+EzcoUfEMBUqe4odFJzl5+SSnrpzi5OWTCT+nrpxi0/FNnLx8knPXkgebP1f+hERfJn8ZKheqzJ1hd1I1rCpl85eVbwDCZZLcc5iAAJPg7VvuVqvdUrOmmTN/5UrK/f9Hjpgbh6pVM8///tv22qFDJnFaUxatJG/PPoFPnWq6dyxW0rYXHZ18/n7S5G4/v92ilOPzzZ5tZijZ7wcmsdt/Q3BlQFVrWPZrAFwuSsCZorQsn0ofFBB3M46Tl08ScyGGI+ePJPwcPn+YI+ePsObomkQfALn8c1G5sEn2tYrWonbx2tQuVpsSeUugZEqPSEKSew5kP9f9+HFbP7ylZk2TrHbuNLXjnTl61AyWFi1qnm/ZAgUKmNbz4cO2hJ4nj+OWu31r+uJFW8s9d27HyXjSpOTbLl5MnIytfn97SiXvqgHn89iTJndX/PwzPPqoe8cE+QdRKl8pSuUrRYNSDRzuE3slll2xu9gdu9v8Pr2bzcc38/2O79GYP6BISBFqF69NnWJ1qF+qPo1KN6JoaFH3ghHZjleTu1KqM9C5UtKRM5Gh7JP7sWPJE7g1Y2b7dteSe1iYeX7ihNn/yBHTcrdmuP7nP7BggZlJ42c3P8u+5X7tmi0Bly5tpi5qbfryLXv2mFILmzZB4cK27WfOpN5ydzSH3pPJ3dH7ekJYSBhNyjShSZkmibZfvH6RLSe2sPHYRjYd38Sm45sYFT2K+Fsm8EqFKtG4dGMal25Mo9KNqFakGn5KJsflJF5N7lrr+cD8qKioJ70ZR05TvLitC8VRy71iRTOwmtqg6tGj0Lw5FCli21aihEnghw+bc+TNaxYWmT0bYmJMcrZYLfegIJPcrZZ76dLmg2L5clOOwF7z5ubbgb0zZ2zz4pOWVgDXk7vVszFwoONupJS4MkbhSXlz5aVxmcY0LtM4Ydu1G9fY8O8G1h5dy5qja/h5789M/XsqAIVzF6Z1hda0rdCWNhXaUK5AucwNWGQ66ZbJgYoXN8nzwgWTUJP2uQcEmH50K7lfvGi6Vuy7dS9fNl0gZcua14KCzM1KJUqYpL5li2mp33mnrU9+587kyT0oyHw4XL1qa7lbs2y2OKgMMGiQ+fDYu9esMnXffam33MF5cr90CUJDk/erf/aZ7bGj7uzXXzeVPK3aP+PHO37fzBQcEJyQ8F/kRbTW7DuzjzVH17D80HKWHljK7O2zAahYsCJtKrShQ6UOtKvYjpDADLy5QniFfE/LgYoXNy1da23VpC13MNMWt20zNeeLFjX1bqzBUTA13G/ehCZNTPKzumaKF4dy5cxMmLVroVYtk+AheWv41CmT2HPntrXcc+c2286eNXXpLTNnmtetbqJKlUwLHxInd+tOVHvOWu4xMeabxaefpni5krl+3VSMjIx0bf8rV8yNTSnNtc8ISikqF65M78jeTO06lZjBMex4ZgejO4ymepHqTN86nXtn3Uvh9wvTZUYXvtz4JScvn8zcIEWGkZZ7DmQl802bzO+kLXcw/e7TpsEjj5jW6ZIlZtWnn382re9ly8y88Ca3u4LDwkyruUQJ04KPjzezZd580yTrQoWSD6rGxprjbt60tdzz5DH7Xr2a+EaqsmVNC9teoULmd79+trIDjhY9AcfJ3epK+fFHk6hXr3Z8bNKWu7trzfbpY7qlcuVK/I0gsymlqFakGtWKVGNA/QHE34xn1eFVzNs9j3m75zF/z3zUfEXD0g15oPoDPFDjAYrndfDJL7IEabnnQEmTu6OWe6NG5vezz5rVlhYtMgOl1q31y5aZxTKshGu13EuUMAOojz8OK1eaue5Kma6ZpC13K7nbt9xDQ80CJAAbNtj2tbbZs5L7v//a5tw74qzlbq3kFBxMQh0ZZ/7803zgQOK6N66YbXpCfG4B8kD/QFpXaM3ojqM5NOgQm5/azBst3uBy3GWeW/wcJT8qSauprZi0YRKnr2Ty1w6RbpLccyArmW/caH47ark3a2bKBowZY1robdrAa6+ZhSuWLDEfDPaDnfbJvXx5U1PG/rx33um45V6kiEmuSVvukLgeTNJBVDA3X7nCWXK3nD/vvCYNmLGFBg1M3f3Tp1OvNx8ba2rqHz2auEaOux8KmUkpRUSxCIY2H8rmfpvZ8cwOXm/2OjEXYui7oC/FRhWj0/ROzNw2k2s3nHw9Ej5FknsOZCXd7dtNUrOfVmjPfhYMmOSWP78pnau18+TuSLVq5sPCfv76qVOOW+5WcgdTAvmbb0yyTMrPxX+9VnIPDHT8+p9/mvEBZ6z69OvWwUMPweDBiV9fsSL5MSdPwk8/mdo6Fl9O7klVK1KNN1u+ye5nd7Ox70YGNxjM1hNbeej7hygxqgQDfxnI38f/Tv1EwmskuedAwcGmJRwfb5Kmq0kyXz7o39/MtMmTB+66y/ZatWrmXEk/ECzWoOqIEeau0Bs3zOBnWJiJx5rnbt9yBzOQ+8gjzmNKrTsFbMnd2QcP2LqoHLGuz61bjm+Sclae+aOPEj+/lQXX5lZKUbt4bd5v+z6HnjvEkkeW0K5iOz7f8DmRn0cSNTGKz9d/zuU4B3eJCa+S5J5DWV0zjrpkUjJwoEnGzZsnbgk//bSpDOnsg8KaDvnxx/D++7YWvJXcr15N3ucOEJVyORd69HDcH59Uask9JdZ8+D173FudyX62D2StlrsjfsqPthXbMrP7TP59/l8+7fApcTfj6PdzP0p9XIqXfn2Jw+cOp34ikSkkuedQVnJ3NJiakjvuMOuUfvJJ4u3+/slns9grW9bMFrFYNd/tp0JaLfeSJc2NT0uWuBbTwoUmnqJO7riPjzffFBwtGO4K+8VGHFWcdJV9UbOzZ53P7HHF99+n/G0joxUOKczA+gP5u9/frO6zmjYV2jAqehQVRleg++zu/H7kd5cWIRcZR5bZy6HS2nIHM9jqbsUIf39znMWa5uio5R4UZGbjtG3r2rkbNDA3NznrU7f6zNPacrdPwq6uKmWxz28LF9oeFyqU/O5bd3TvnvJyiplFKUWTMk347v7vODjoIC80fIHfDv5G06+a0vSrpizcu1CSvJfIMns5VFpb7umxeDHMnWse299AZd/nnlLrPzXOkrt185Wzln1q7FvI6WltA/zwg+1xSoO4YLq6HBVL81Vl8pfhvbbvcXTwUcZ0HMOR80foNL0TdSfWZc6OOdzSWXDQIQuTbpkcKj0t97RSypZgreRerJjplrlyxbSw0/M5n1rL3dlgb2qWLrU9Tm9y79Yt5de1NjOEjh2DCROgb9/0vZ83hAaF8uxdz7Jv4D6+7PIll+Iucf9391PjsxpM3zpdknwmkeSeQ3mj5Q62BLt1q+l+KVDAtNytG3xcnbvuSGotd/tZOGmV0Ytf//WXuas3rV1IviTIP4j/1v4vO/vvZGa3mQT6BdLzh57U+bwOP+/5WbprMpgk9xwqMtIMXoaHZ+77WsndWiREKdNyt2Rkyz09XT4Wd/PRY4+l/PqiReYaxMSYm58aOC7rDiQvyZBV+Pv506NmDzb328y0+6ZxKe4Sd8+4m6ZfNWX1YSc1H0S6SXLPoapVM0kvs0vp58tnS8JWl1BwsO31jEju1reClFaVykz2HxDWrKOtW8300pQ89pip+WN9WDlz/Di0aGHukB0xwv1B4Izip/x4OPxhdvbfyfhO4zlw9gDNpjTj3ln3cuDsgdRPINwiyV1kKqVsrXerSyijk7slaXJfvz75PgMGpP39XWWf3BcvNr9PnYIdO1I+zroT1qpx48ynn5q6PpUrm9LEuXKZu2V9RaB/IP2i+rFv4D7ebvU2v+7/lerjqjN0+VCuxKdQJ0K4RZK7yHRWcrda7p7qlkltznnS5O5olamk8/czQg0Hy6v26uX68c8+69p+9uMD99zj+vkzS0hgCP/X9P/Y/exuulXvxlur3uLOsXeaJQSlPz7dJLmLTGfNmHHULZOeAdXUqi660i3jaimG9HB3lSeL9eH13Xcp7+csLzr7ZnDjBrzyiuNa+JmhZL6STLtvGqv7rKZwSGG6f9ed+2bfx78XM2jtwhxCkrvIdBnVck96u/+DDyZ+7it97t7Su7fj7XPnwjvvJC+IltmalGnCuifX8X6b91m0bxHVx1Vn0oZJMnUyjSS5i0yXNLl7qs/dWpPVGpjs1i3xbCD75P7FF+6du1y5tMeVXseOmda1/YLinmQtBp7eOfyeEOAXwIuNX2Tr01upU7wOfRf0pfXXrdl/Zr+3Q8tyJLmLTOcsuQcEJG7Fu2voUFOh0So/rHXiEsP257YWHXHVjz+mPa70KlECxo3LuPO7Ux8ns1QqVIlljy1jUudJbDq2iVoTajF+3Xjpi3eDJHeR6cqUMQnFWizbSrr58qUv0bz5Jvz2m+0cWifuRw4IgOHDoXNn988dGZm5d/Mm9dxzru13+bLz0sLO8uLvvzvefvWquZZffeXae3uaUoon6jzBtme20aRME55Z+Aztv23P0fMpLLslEkhyF5nuwQfNwhfWXZhWyz0jSgxZKzBZKzm9/rrzaYGp3eS0YIHHwvKYP/+0Vdi8ft3cmPbBB6kfd+KE7bH1rSBp8j9+3PwePjz9caZHqXylWNRzERM6TWDt0bXUHF+TKZunSCs+FZLcRaYLDEw8DdHTyd2+5W6xElVK8uZN+fX0dBlllAYNzHhAvXpmCcCUWLOJZs8230KcLQielDdy6JkziZdZVErxVNRTbHl6CxF3RNBnXh/umXkPxy+58B82h/J4cldKVVBKfamUmuPpc4vsyUqank7u9uxryTuT2t26Kd0kZXUxecv69aZMcko2bza/rW8uSevBWwt5+4LChR2vm1uhYAVW9F7BR+0+Ysn+JdT4rAazt/tQ4D7EpeSulJqslDqplNqWZHsHpdRupdQ+pdTLAFrrA1prN4erRE5mtdzTM8fdEa1NAps2LfV9J05MXI7XkdTugPW21OrYAIwda7seWbVXw0/5MbjhYDY9tYmKBSvSY04PHpzzIKevpPLVJYdxteU+Behgv0Ep5Q+MAzoC1YGHlFLVPRqdyBEyquWutRkIffhh5/seOGCKcT35ZOolgV1J7mmtGZ9ZUiuvYI0rnDvnm7No7FUrUo21j69lZKuR/LDzB2p8VoP5u+d7Oyyf4VJy11qvAs4k2XwXsO92Sz0OmAn44E3OwtdZXSaeHlB1pWVavjxUd9Ik+fXXxM9TSu5t2pjf1jTMrLD+jKPr07kzREebdWk//jjzY0rK6kpyJsAvgFeavsK6J9dxR5476DKzC33m9eH8NVndLT197iUB+zlJMUBJpVRhpdQEoLZS6v+cHayU6quUWq+UWn8qo+7OEFmCn5/p73ZUcyUtHA2opkXTpomfp5Tcx4+HvXttxdB8vQsnJaNHJ/6dksuXM7Z7p3Zt1/aLKBbBX0/8xStNXuHrv7+m1oRa/H7EyRzPHCI9yd3RlzattT6tte6nta6otX7H2cFa64la6yitdVSRtC6RI7KNvXvNsnKe4KnuhKR1ZlJK2EFB5gMqKMg89/f3TAzeMHNm4uf2yXvUKHN9L12C+vXN1MsRIzI3PmdyBeRiZOuRrPnvGgL8Amg+pTlvrHiDG7dSKTqUTaUnuccApe2elwKk0o/wun79zG/7BbnTIumHhCutcauLKSDAtq1gwfTFkVFcbXEfOWI+tM6ds7XmT582q0YBzJjhmVjGjjXfBNKrQakGbHpqEz3De/LmyjdpMaUFh88dTv+JHTh/PvVSzd6SnuS+DqislCqvlAoCHgTcqhqtlOqslJp4/rz0jwnPadbMJIvSpVPf15FixUyrPWnL3T5hO2Mldytx1q9v+vV9kTvdKfHxiT8s7Y/duRMaNkxfLPPnm8Hel15yPF5x8SIMG+a88ufNm7Bnj+15vlz5+Prer/n23m/ZcmILERMi+G57KuU006BFC891J3qaq1MhZwDRQFWlVIxS6nGt9Q3gWWAxsBOYrbV2axEwrfV8rXXf/Flh9EnkGIcP2269t+dKV0utWub3v7e/w3qz4FhqtLYVW3PF1q3OxzP++MP5ezj6ELlxI3GivnTJ/F62zLbmreXCBVOSePhw598SXn0VqlaF/Unqi91XuSe1/9xM2dA7eWDOAzzx0xNcjrN9PYiOTl/LO+mA72efwf33p/18nuTqbJmHtNbFtdaBWutSWusvb29fqLWucrt/fWTGhipE5ggKMj9WIqtY0fZaat0GSdspmb0AuTsmTYI6ddw7xvqS7Wqrv0cPxzXyixaFO+4wlS7tE+Tu3cn37drVVkbC2QLlq1aZ3/ZlFaztq+ZVoOjPq3m16at8uXEyFd6tx9YTWwFo1MizLe/+/WGOj9y+6dXyA9ItI3zdkiWwZo3teUiIbT78558n3z8rDaTu3m3WWXXHuXOu7XfzpvlwdLawyNmzpsRA7drmp2dP5+ey+vZTYn3YOPt7/HQgI1qNgK+XcvLCWepNqsf4deMB96f6HDrkWjkLb/NqcpduGeHr2rY1LUx7W7eawmd9+5o1UO37epMmd63htdcyPs7M5qzl/p//OF6Uu00bUzZ5377E2//5x733cjYTavvtDuGkC7Qkc7AVTPibVuVb8czCZ6BHNwg2pUOvXXOti6Z8efONLLWVv+xjtgb5M5MUDhPCTXfcAVFR5nG7dmYhaoujlvu992ZsPXZvcFSH5/774ZdfTOXNpMl/2TK4777E1yqttm0zCVMpmDzZJNqLF22vW685dbkon9ZfwKh2o6DKAugXyZoja3jiCdNFs3Kla3E88kjKr8fF2T7kHH3Ly2jSLSOEByXtX7aSnK/fyu8JrvY1T5/u3nmvXLEVOXviicSraz3+uPMukogIM8MGbKtNWapU9uP5hs/Dl2vglpkTv+D8SFA3adHCeSy//WZ7PGuW7bFStm8PYAaqCxVKPAazd6/Zb9QoM5Mr6fiAp0m3jBAe5KhbJidK6e9OSys2aQVLV2zZYurdAyxfnriEMMDSpcC/9eDzTXS7swfno16Dx9pCXue367Ru7fz97AvPbdhgBt/tly60Xn/hBYiJMdNHjx1z729yh3TLCOFBzgZUc0LL3V5q5ZO9Ydu2xM9ff/32g+v5mN3jW5j7FZT8E/pFMH/3z26f335a6Ztvpr7/wYPw0ENuv43LJLkL4UGpdcuk1k+bXaQ0m8SatpjZmjRJ/Dzx3HwFm3vDxA1wsQRdZt5Nr2n/I+5mHNu3Q5cuiQfOHbGvxRMd7VpM1vz+jODCPXdCCFel1i3jyl2uwoti74Qv/oS2L/I1H7H9y5Vs+L+ZcKaSy9NA3ZGR3+hkQFUID3KW3K0BvZCQzI1HpMGNYPhlDNX+/pGNBw/AU7UhfJrLyxI6s2iRZ8JzlQyoCuFBzvrcrTsrXVnuT/iGnT92RY/fDMcjodsj0LU3BKW9H2XFiuTbks779yTpcxfCg5z1ubub3A8c8FxMIh3Ol4Gpy2HFUIj4Gp6pCZXdH2x1JiO6eiyS3IXwoLx5Ez+3krt1M4sryb1aNd+tJJkj3QqAFW/C5NUQFwo97zZ3bKUwZdIXSJ+7EB7UvLmpS27d0GNVibRKGJQta26Rt1+0+8UXE5/D1UFXX5xumK0dbQyfb4JlI6HqfOhfDRp+BP5Oqpl5mdI+cJdFVFSUXr9+vbfDEMKjNm0yC3QrBbduwbx5psKhNUPC+v3SS/D++7bjwsPNDTgpzaR4/HFo1SrlglsiAxXaBx0HQOVFcKYCLH0XdnTH8QJ1KTt+PHn9IlcppTZoraMcvSbdMkJkkNq1bQnaz8/UmLFP2M6StyvtLRmY9bIzlWDaL/DNIogPhQcegMcbQ4VfcbfS5NatGROiJHchvOTgQVNOOLW5zoczZoU44Qn728OETTDvC8h/BB5rB080hCrzcTXJz5+fMaFJchfCS8qWNYtFdOyYeHvSlnuZMsmP1TrnlTTwWdofNj0On+6H+Z9D6Al4uAv0rwH1R0PwuRQPt7+z1ZMkuQvhZc2bm3VIk1q7FqZONY9HjXK+lJ3wETdzwYa+MGYP/PA1XM8LHQfB/0qYOfKVFoFffKqn8RSvDqgqpToDnStVqvTk3r17vRaHEL7AaonXqJG8yFXSfV591QymVq+eObGJNCq+EaImQI1ZEHwBrhSGnffB7s5wqCXE5QHSXj00pQFVmS0jhI9wJ7lfuGDm1H/8MTz/fObEJ9Ih4BpUXGKSfNWfINcluBkIR5rAytfRB1um6bQyW0aIbMa6WapvX9u2pPPlhQ+5EQy7u8AP0+D9WJi6DP54DnKfBj8X1+tzk9SoE8LHuPNlOjTU9rhgQc/HIjLAzVxmLdeDreDX91PfP42k5S6Ej1i40Pz+5JO0HV+8uMdCEdmAJHchfETHjqbV3rZt2o7v1css4QbQpo3n4hJZk3TLCJHFffopbNxoBlutxaOLFfNuTML7JLkLkcUNHGh7bJUc9oFJcMLLpCqkENlI3brmd9euXg1D+ABZiUmIbKRaNVM7vnt387xECe/GI7xHBlSFyGYCA83vRYtg3TrvxiK8R/rchcim2rc3v/394eZN78YiMp+03IXI5mJjoWJFb0chMpskdyGyuQIFoEgRb0chMpt0ywiRhSxZkrjkgKtkamTOIy13IbKQtm3NAh/uslruS5Z4Nh7huyS5C5EDTJkC48ebsgS7djnfr1Mn+PzzTAtLZCCp5y5EDuRoib6gILh+3fnrIuNkxGId0nIXQvDWW/DXX96OQniSVwdU7ZbZ82YYQuRoDz8Mr73m7SiEp0n5ASFyOGsRbpG9SLeMEDmQtbB2s2YQ4OD7+733Zm48wvMkuQuRA61aBdHRsHKl49elNZ/1yU1MQuRAhQubn7QKDoZr1zwXj/A8abkLIVJk1Yi316IFzJ2b2ZEId0hyF0I4FRrqeM67zIP3fZLchRDJ2CdvRzfYKGVKIXToIOu1+ipJ7kIIp5zdOakUhITAL78kLyf8yy+Oj5Gl/zKXJHchRDKOul1KloS1a81jR4tyA9x1l2nNC++T5C6ESMZK7gUL2lrvc+dCw4bmebt2tn3z5bM9vnXL+Tm7dPF4mCIFktyFEMmEhMBnn5n58Kl59lnb45QKYJUoYV4fM8a2rVattMcoUibJXQjh0NNPQ4UKqe9nLcgNtuT+yCO2bW3bJt6/VCnb4yFD0h6fSJkkdyGES5xNf7RvrYeHm99Wi/zpp22vW8ffc0/q50zLgiQiMUnuQoh0sZJ3UJBZEMReaGjy5K4U/P67WRTEPrm//rrtcYMGGRdvTuHx5K6UClVKTVVKTVJK9fT0+YUQmcvVhSSaNYPcuc3j9u3N7/vuS57cARo3hr59Ex8/fLjt8auvpi1WYeNScldKTVZKnVRKbUuyvYNSardSap9S6uXbm+8D5mitnwRkfFyIbMJZF0q9epA/f+KWd61aJqk3bJjy8c7q2xQqZHvcooXboQpcb7lPARLNXlVK+QPjgI5AdeAhpVR1oBRw9PZuNz0TphDCVxUoAOfOmZa7I2+9ZebI16uX/LVcuczvJk0cH1unDtxxhyeizHlcSu5a61XAmSSb7wL2aa0PaK3jgJnAPUAMJsG7fH4hRPbVqBHExCSeD++KixdNWWKRNulJviWxtdDBJPWSwA9AN6XUeGC+s4OVUn2VUuuVUutPnTqVjjCEEFlV0q6awYNt5Qvy5DGDtCJt0lPP3VEPnNZaXwb6pHaw1noiMBEgKioqjWt/CyEymqsDqp7w0UeZ917ZXXpa7jFAabvnpYB/0xeOEMJX+UqZ3+3bISLC21H4vvQk93VAZaVUeaVUEPAg8JM7J1BKdVZKTTx//nw6whBCZCQ/L4+cJf3mUL06FC/unViyElenQs4AooGqSqkYpdTjWusbwLPAYmAnMFtrvd2dN9daz9da982fP7+7cQshMsl335kqkL7UWp4wAR591NtR+DaX+ty11g852b4QWOjRiIQQPqVCBfj004w5d5Uq5veTTzrfx1F3UNmy8PXX8M037r9n5crm28C+fe4fmxGskg2e5tUvXNItI0TOdscdJtE+9lj6zvPBB9Cxo/NxgdBQ2+NHH7UVL/OFbyN3350x5/VqcpduGSFEalKarTN3LgwbBi+8AAsXOq8n//TTtscPPGD7EEh6bvs7ajNLiRIZc165yUgIkWXdcw+88Ubibf/8k/h5nz62ZP7ee1C1qu25/YdBu3auTfu87740h+tQRs1Ckm4ZIUS2UqKEmVFjKVLE9thRETPL4sWpn/uZZ2DmzPTFl1mkW0YIke2sXw9Ll5rHd9/tWi16VwUGJi5s5qukW0YIke3kzg2tW5vk3bQp3H+/2d6pk/mdtM/dujO2tN1tmQEO5hJax3myYkq27JYRQojUPPFE+s8RFWUSec2a5rmzhPrFF7bHe/Y4P5+fH8TGpv6+b7+d+j7WdFBPk+QuhPBpbdt6vr5Nl9srTXz6qUmuD92+kydfPlvit2/FW+w/FJzVoreUKgVlyqQeS0bdASwDqkKIHKd/fzh7Ftq0gd27oVgx22ue+iApWtQz50krGVAVQmQJY8bAokWeOZdSZpGR1PZ5773k2+xVquT8+EqVoHZt12LJCNItI4TIEp591rY2a0ayT7YvvZT4tbJlHe9rP43y/fdhwQL48svEUzIzmyR3IYRwwfz58Nxzjl8rV872ODTUzMrJk8c8X7s25fNKy10IITKBsz73u+8Gf//E26xBVftpk0nvYLV/rXz59MfnKhlQFUIIB1xpUf/wA4wbZypnWuwHZ8FMw3Skbl3X3yctZEBVCCHSqHhxU5IgJfbJ2/5bQUhIxsRkkW4ZIYTwomzZchdCiJzK6rAICsqY87u0EpMQQoj0GzoU7rzTlBquWhWmToX69TPmvSS5CyGEA57sLnn+eTOA+vDDibf/73+ee4+kvJrclVKdgc6VUrrNSwghsrhRozL/PWW2jBBCeEjjxt6OwEa6ZYQQwgNOnIC8eb0dhY0kdyGEcMDdPndvV4FMSqZCCiFENiTJXQghsiFJ7kIIYeeDD7wdgWdI4TAhhLDzwgueX9bPG2QqpBBCZEPSLSOEENmQJHchhMiGJLkLIUQ2JDcxCSFECh58EBo08HYU7pPkLoQQKZgxw9sRpI10ywghRDYkyV0IIbIhSe5CCJENSXIXQohsSMoPCCFENiTlB4QQIhuSbhkhhMiGJLkLIUQ2pLQP1LZUSp0CDt9+mh9I2gmfdJv98zAgNoNCcxSLp45LaR9nr7m6Paddr5Red/ffU9Lncr3cu16QcddMrldyZbXWRRy+orX2qR9gYmrb7J8D6zMzFk8dl9I+zl5zdXtOu17uXjO5Xhl3vTLymsn1cu/HF7tl5ruwzdE+GSGt7+PKcSnt4+w1V7fntOuV0utp+fck1yvlbXK9Ut7uE9fLJ7pl0kMptV5rHeXtOLIKuV7ukevlPrlm7smo6+WLLXd3TfR2AFmMXC/3yPVyn1wz92TI9cryLXchhBDJZYeWuxBCiCQkuQshRDYkyV0IIbKhbJfclVKhSqmpSqlJSqme3o7H1ymlKiilvlRKzfF2LFmBUqrr7X9b85RS7bwdj69TSlVTSk1QSs1RSj3t7Xiygts5bINS6u70nCdLJHel1GSl1Eml1LYk2zsopXYrpfYppV6+vfk+YI7W+kmgS6YH6wPcuV5a6wNa68e9E6lvcPN6zb39b6s30MML4Xqdm9drp9a6H/AAkCOnR7qZvwCGALPT+75ZIrkDU4AO9huUUv7AOKAjUB14SClVHSgFHL29281MjNGXTMH16yXSdr1eu/16TjQFN66XUqoL8DuwLHPD9BlTcPF6KaXaADuAE+l90yyR3LXWq4AzSTbfBey73fKMA2YC9wAxmAQPWeTv8zQ3r1eO5871UsZ7wC9a642ZHasvcPffl9b6J611IyBHdpO6eb1aAg2Ah4EnlVJpzmEBaT3QB5TE1kIHk9TrA6OBsUqpTmTebdFZgcPrpZQqDIwEaiul/k9r/Y5XovM9zv59DQDaAPmVUpW01hO8EZwPcvbvqwWmqzQXsDDzw/JZDq+X1vpZAKVUbyBWa30rrW+QlZO7crBNa60vA30yO5gswNn1Og30y+xgsgBn12s0pgEhEnN2vVYAKzI3lCzB4fVKeKD1lPS+QVbutogBSts9LwX866VYsgK5Xu6R6+UeuV7uyfDrlZWT+zqgslKqvFIqCHgQ+MnLMfkyuV7ukevlHrle7snw65UlkrtSagYQDVRVSsUopR7XWt8AngUWAzuB2Vrr7d6M01fI9XKPXC/3yPVyj7eulxQOE0KIbChLtNyFEEK4R5K7EEJkQ5LchRAiG5LkLoQQ2ZAkdyGEyIYkuQshRDYkyV0IIbIhSe5CCJENSXIXQohs6P8Byr72az6hAgoAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "pyplot.plot(SGD, \"b-\", label=\"Stochastic Gradient Descent\")\n",
        "pyplot.plot(GD, \"g-\", label=\"Gradient Descent\")\n",
        "pyplot.legend()\n",
        "pyplot.loglog()\n",
        "pyplot.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cKia1SB14pr"
      },
      "source": [
        "Task 10: Example Evaluation\n",
        "---------------------------\n",
        "\n",
        "We want to see what the network has learned.\n",
        "Therefore, we evaluate some data point that would represent a typical Swiss student (except for the school entry, where we select one of them randomly).\n",
        "We select appropriate information for all inputs, see https://archive.ics.uci.edu/ml/datasets/Student+Performance for an explanation of typical values.\n",
        "\n",
        "Also remember that input data need to be normalized before feeding it to the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgNS9sJH14pr",
        "outputId": "21c84b4b-64d8-44ab-8f22-9a349839e965"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction :\t [[12.95429357 14.18527714  8.67407125]]\n"
          ]
        }
      ],
      "source": [
        "# select a specific example\n",
        "example = numpy.array([[\n",
        "  1., # BIAS\n",
        "  -1, # school (select -1 or 1)\n",
        "  1, # gender\n",
        "  18, # age\n",
        "  1, # adress\n",
        "  1, # family size\n",
        "  1, # parents living together\n",
        "  1, # mother education\n",
        "  1, # father education\n",
        "  1, # travel time\n",
        "  4, # study time\n",
        "  0, # class failure before\n",
        "\n",
        "  1, # support from school\n",
        "  1, # support from the family\n",
        "  1, # paid extra support\n",
        "  -1, # out-of-school activities\n",
        "  1, # nursery school\n",
        "  1, # want to do higher ed\n",
        "  1, # internet access\n",
        "  1, # romantic relation\n",
        "\n",
        "  1, # relation to family\n",
        "  3, # amount of free time\n",
        "  1, # go out with peers\n",
        "  6, # alcoholic drinks during week\n",
        "  1, # alcoholic drinks in the weekend\n",
        "  1, # health status\n",
        "  0 # days of absence\n",
        "]]).T\n",
        "\n",
        "example = normalize(example, mean, std)\n",
        "\n",
        "# compute network output\n",
        "prediction, h = network(example, Theta2)\n",
        "print(\"Prediction :\\t\", prediction.T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARupZwp014ps"
      },
      "source": [
        "Task 11: Influence of Data Dimensions\n",
        "-------------------------------------\n",
        "\n",
        "We modify particular dimensions of the input and evaluate how this changes the predicted grades.\n",
        "Particularly, we test:\n",
        "\n",
        "* if it makes a difference to be female (-1) or male (1) at index 2\n",
        "* if the student takes paid classes (-1 or 1) at index 14\n",
        "* if a romantic relationship influences (-1 or 1) the results at index 19\n",
        "* how much of daily alcohol consumption (1-6) is still OK at index 23\n",
        "\n",
        "Note that the indexes include the fact that we are omitting some input dimensions, so they might differ to what is listed on the webpage.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZCnP9Be14ps",
        "outputId": "6005278f-319a-4cf8-a825-816cac5bb33d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "For index: 2, value -0.9481763873554659, the predicted output is [[12.95672823 14.1649579   8.67044622]]\n",
            "For index: 2, value 1.0546560886092884, the predicted output is [[12.95429357 14.18527714  8.67407125]]\n",
            "For index: 14, value -0.9196708066060205, the predicted output is [[12.94423069 14.14026909  8.62990333]]\n",
            "For index: 14, value 1.0873455945507646, the predicted output is [[12.95429357 14.18527714  8.67407125]]\n",
            "For index: 19, value -0.7084498152194034, the predicted output is [[13.17262112 14.11204308  8.47218149]]\n",
            "For index: 19, value 1.4115325863841144, the predicted output is [[12.95429357 14.18527714  8.67407125]]\n",
            "For index: 23, value -0.5406986566036547, the predicted output is [[17.10796171 16.6049923  12.67616791]]\n",
            "For index: 23, value 0.583385392651312, the predicted output is [[17.88478987 17.83026278 13.49235493]]\n",
            "For index: 23, value 1.7074694419062786, the predicted output is [[17.28435371 17.77838633 13.21654874]]\n",
            "For index: 23, value 2.831553491161245, the predicted output is [[14.9211371  16.56179874 11.3060937 ]]\n",
            "For index: 23, value 3.9556375404162116, the predicted output is [[13.36128357 14.80440318  9.3200821 ]]\n"
          ]
        }
      ],
      "source": [
        "def predict_grade(x,theta, index, value):\n",
        "  x = x.copy()\n",
        "  x[index,:]=value\n",
        "  return network(x,theta)[0]\n",
        "\n",
        "# run this with the 4 modifications and their according values as seen above\n",
        "# note that we use normalized data in all cases (for X, example and values)\n",
        "for index in [2,14,19,23]:\n",
        "  for value in numpy.unique(X[index,:]):\n",
        "    print(\"For index: {}, value {}, the predicted output is {}\"\n",
        ".format(index,value,predict_grade(example,Theta2,index,value).T))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Assignment04.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('DL')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
