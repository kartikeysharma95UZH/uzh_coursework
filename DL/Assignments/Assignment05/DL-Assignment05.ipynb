{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 5: Classification in PyTorch\n",
    "=======================================\n",
    "\n",
    "\n",
    "Microsoft Forms Document: https://forms.office.com/r/4PAnYRs2Bf\n",
    "\n",
    "\n",
    "Task 1: Dataset Loading\n",
    "-----------------------\n",
    "\n",
    "We use two different datasets, the spambase dataset https://archive.ics.uci.edu/ml/datasets/spambase for binary classification and the wine dataset https://archive.ics.uci.edu/ml/datasets/wine for categorical classification.\n",
    "Both datasets are avaliable on the UCI Machine Learning repository.\n",
    "In the first dataset, the target values are stored in the first column, while the rest is input.\n",
    "For the second dataset, the target is stored in the last column, the rest is input.\n",
    "\n",
    "When running with pytorch, samples should be stored as datatype ``torch.tensor``, and split between input sets $\\mathbf X = [\\vec x^{[1]}, \\ldots, \\vec x^{[N]}]^T \\in \\mathbb R^{N\\times D}$ and targets.\n",
    "There is **no need** to add a bias neuron to the input, and the transposition of the data matrix is different from what we have seen before.\n",
    "\n",
    "For the targets, we have to be more careful as there are differences w.r.t. the applied loss function.\n",
    "For binary classification, we need $\\mathbf T = [[t^{[1]}, \\ldots, t^{[N]}]]$ to be in dimension $\\mathbb R^{N\\times1}$ and of type ``torch.float``.\n",
    "For categorical classification, we only need the class indexes $\\vec t = [t^{[1]}, \\ldots, t^{[N]}]$ to be in dimension $\\mathbb N^N$ and of type ``torch.long``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# download the two dataset files\n",
    "dataset_files = {\n",
    "  \"spambase.data\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/\",\n",
    "  \"wine.data\": \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/\"\n",
    "}\n",
    "for name, url in dataset_files.items():\n",
    "  if not os.path.exists(name):\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(url+name, name)\n",
    "    print (\"Downloaded datafile\", name)\n",
    "\n",
    "\n",
    "def dataset(dataset_file=\"wine.data\"):\n",
    "  # read dataset\n",
    "  data = []\n",
    "  with open(dataset_file, 'r') as f:\n",
    "    ...\n",
    "\n",
    "  print (f\"Loaded dataset with {len(data)} samples\")\n",
    "  \n",
    "  # convert to torch.tensor\n",
    "  ...\n",
    "\n",
    "  if dataset_file == \"wine.data\":\n",
    "    # target is in the first column and needs to be converted to long\n",
    "    X = ...\n",
    "    T = ...\n",
    "  else:\n",
    "    # target is in the last column and needs to be of type float\n",
    "    X = ...\n",
    "    T = ...\n",
    "  return X, T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1: Assert Valid Data\n",
    "-------------------------\n",
    "\n",
    "Load the wine dataset and make sure that the dataset is in the correct dimensions, i.e., $\\mathbf X\\in \\mathbb R^{N\\times D}$ and $\\mathbf T \\in \\mathbb N^N$.\n",
    "Also assure that all class labels are in the correct range $[0, O-1]$.\n",
    "\n",
    "Load the spambase data and assure that all dimensions are correct and that class labels are in range $\\{0, 1\\}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load email data\n",
    "X, T = dataset(\"spambase.data\")\n",
    "# assert that everything is correct with the dataset\n",
    "...\n",
    "\n",
    "# load wine data\n",
    "X, T = dataset(\"wine.data\")\n",
    "# assert that everything is correct with the dataset\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Split Training and Validation Data\n",
    "------------------------------------------\n",
    "\n",
    "Write a function that splits off training and validation samples from a given dataset.\n",
    "Use randomly 80% of the data for training, and 20% for validation.\n",
    "\n",
    "What do we need to assure before splitting?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_training_data(X,T,train_percentage=0.8):\n",
    "  # split into 80/20 training/validation\n",
    "  X_train = ...\n",
    "  T_train = ...\n",
    "  X_val = ...\n",
    "  T_val = ...\n",
    "\n",
    "  return X_train, T_train, X_val, T_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Input Data Standardization\n",
    "----------------------------------\n",
    "\n",
    "Implement a function that standardizes all input data for the training and validation set.\n",
    "Return the normalized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X_train, X_val):\n",
    "  # compute statistics\n",
    "  mean = ...\n",
    "  std = ...\n",
    "\n",
    "  # standardize both X_train and X_val\n",
    "  ...\n",
    "  return X_train, X_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Network Implementation\n",
    "------------------------------\n",
    "\n",
    "Implement a function that returns a two-layer fully-connected network in pytorch.\n",
    "Use tanh as activation function, and provide the possibility to change the number of inputs $D$, the number of hidden neurons $K$ and the number of outputs $O$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def Network(D, K, O):\n",
    "  return torch.nn.Sequential(\n",
    "    ...\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Accuracy Computation\n",
    "----------------------------\n",
    "\n",
    "Implement a function that computes the accuracy of the provided network output (the logits) and the given target values.\n",
    "Make sure that the implementation supports both binary as well as categorical targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(Z, T):\n",
    "  # check if we have binary or categorical classification\n",
    "  if ...:\n",
    "    # binary classification\n",
    "    return ...\n",
    "  else:\n",
    "    # categorical classification\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2: Test Accuracy Function\n",
    "------------------------------\n",
    "\n",
    "Design test data and according logit values with which you can test the correctness of your accuracy function.\n",
    "Make sure that the accuracy will compute the correct values.\n",
    "Test both binary and categorical accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test binary classification\n",
    "# ... design test logits and target values\n",
    "Z = ...\n",
    "T = ...\n",
    "# ... test that the expected accuracy is computed\n",
    "...\n",
    "\n",
    "# test categorical classification\n",
    "# ... design test logits and target values\n",
    "Z = ...\n",
    "T = ...\n",
    "# ... test that the expected accuracy is computed\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Training Loop\n",
    "---------------------\n",
    "\n",
    "Implement a function that takes all necessary parameters to run a training on a given dataset.\n",
    "In this week, we will make use of the whole dataset in each training step, so we will perform gradient descent (not SGD), so there is no need to define anything related to batches.\n",
    "\n",
    "For each epoch, compute the training set and the validation set accuracy, as well as their losses, and return all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(...):\n",
    "  optimizer = ...\n",
    "\n",
    "  # collect loss and accuracy values\n",
    "  train_loss, train_acc, val_loss, val_acc = [], [], [], []\n",
    "\n",
    "  for epoch in ...:\n",
    "    # train on training set\n",
    "    # ... compute network output on training data\n",
    "    ...\n",
    "    # ... compute loss from network output and target data\n",
    "    ...\n",
    "    # ... perform parameter update\n",
    "    ...\n",
    "    # ... remember loss\n",
    "    train_loss.append(...)\n",
    "    # ... compute training set accuracy\n",
    "    train_acc.append(...)\n",
    "\n",
    "    # test on validation data\n",
    "    with torch.no_grad():\n",
    "      # ... compute network output on validation data\n",
    "      ...\n",
    "      # ... compute loss from network output and target data\n",
    "      ...\n",
    "      # ... remember loss\n",
    "      val_loss.append(...)\n",
    "      # ... compute validation set accuracy\n",
    "      val_acc.append(...)\n",
    "\n",
    "  # return the four lists of losses and accuracies\n",
    "  return train_loss, train_acc, val_loss, val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Plotting Function\n",
    "-------------------------\n",
    "\n",
    "Implement a function that takes four lists containing the training loss, the training accuracy, the validation loss and the validation accuracy.\n",
    "Plot the two losses into one plot, and the two accuracies into another plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "def plot(train_loss, train_acc, val_loss, val_acc):\n",
    "  pyplot.figure(figsize=(10,3))\n",
    "  ax = pyplot.subplot(121)\n",
    "  ax.plot(..., \"g-\", label=\"Training set loss\")\n",
    "  ax.plot(..., \"b-\", label=\"Validation set loss\")\n",
    "  ax.legend()\n",
    "\n",
    "  ax = pyplot.subplot(122)\n",
    "  ax.plot(..., \"g-\", label=\"Training set accuracy\")\n",
    "  ax.plot(..., \"b-\", label=\"Validation set accuracy\")\n",
    "  ax.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Binary Classification\n",
    "-----------------------------\n",
    "\n",
    "Load the data for binary classification, using the ``\"spambase.data\"`` file.\n",
    "Split the data into training and validation sets.\n",
    "Standardize both training and validation input data.\n",
    "\n",
    "Instantiate a network with the correct number of input neurons, a given number of $K$ hidden neurons and one output neuron.\n",
    "Instantiate the binary cross entropy loss function.\n",
    "\n",
    "Train the network with our data for 10'000 epochs and plot the training and validation accuracies and losses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "loss = ...\n",
    "# load dataset\n",
    "X, T = ...\n",
    "# split dataset\n",
    "X_train, T_train, X_val, T_val = ...\n",
    "# standardize input data\n",
    "X_train, X_val = ...\n",
    "# instantiate network\n",
    "network = ...\n",
    "\n",
    "# train network on our data\n",
    "results = ...\n",
    "\n",
    "# plot the results\n",
    "plot(...)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 9: Categorical Classification\n",
    "----------------------------------\n",
    "\n",
    "Perform the same tasks with the ``\"wine.data\"`` dataset.\n",
    "How many output neurons do we need?\n",
    "Which loss function will we need this time?\n",
    "\n",
    "How many hidden neurons will we need to get 100% training set accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define loss function\n",
    "loss = ...\n",
    "# load dataset\n",
    "X, T = ...\n",
    "# split dataset\n",
    "X_train, T_train, X_val, T_val = ...\n",
    "# standardize input data\n",
    "X_train, X_val = ...\n",
    "# instantiate network\n",
    "network = ...\n",
    "\n",
    "# train network on our data\n",
    "results = ...\n",
    "\n",
    "# plot the results\n",
    "plot(...)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
