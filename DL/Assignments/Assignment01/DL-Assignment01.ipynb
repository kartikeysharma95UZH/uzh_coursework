{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 1: Perceptron Learning\n",
    "=================================\n",
    "\n",
    "\n",
    "Microsoft Forms Document: https://forms.office.com/r/6pxGSqCxzM\n",
    "\n",
    "\n",
    "Task 1: Data Generation\n",
    "-----------------------\n",
    "\n",
    "Given the number of samples and the means (mu) and standard deviations (sigma) of positive (pos) and negative (neg) data, generate and return data samples including their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(number_of_samples, mu_pos, sigma_pos, mu_neg, sigma_neg):\n",
    "  # create positive and negative data\n",
    "  positive_data = ...\n",
    "  negative_data = ...\n",
    "\n",
    "  # assign positive and negative labels\n",
    "  positive_labels = ...\n",
    "  negative_labels = ...\n",
    "\n",
    "  # concatenate positive and negative data\n",
    "  all_data = ...\n",
    "  all_labels = ...\n",
    "\n",
    "  # anything else to consider?\n",
    "  ...\n",
    "\n",
    "  # return both X and T\n",
    "  return all_data, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Select Data Parameters and Line Parameters\n",
    "--------------------------------------------------\n",
    "\n",
    "We want to select data points such that we exactly know where the ideal separating line should be placed.\n",
    "Note that data samples are not always separable since they are generated randomly.\n",
    "You should determine, which means and standard deviations are useful.\n",
    "\n",
    "Once you have defined your means, you should also define the separating line.\n",
    "The easiest is to provide it as cartesian equation: $w_0 + w_1 x_1 + w_2 x_2$.\n",
    "Note that the separating line is orthogonal to the vector $\\overrightarrow{\\vec\\mu_- \\vec\\mu_+}$, that the normal of the line $(w_1, w_2)^T$ is orthogonal to the line, and that $w_0$ should be selected such that the line $\\vec w$ is in the middle of $\\vec\\mu_+$ and $\\vec\\mu_-$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, T = dataset(100, ...)\n",
    "\n",
    "w_manual = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1: Linear Separability Test\n",
    "--------------------------------\n",
    "A line $a = f_{\\vec w}(\\vec x) = w_0 + w_1 x_1 + w_2 x_2$ linearly separates the data $(X,T)$ if $\\forall n: a^{[n]} t^{[n]} > 0$ for $a^{[n]} = f_{\\vec w}(\\vec x^{[n]})$.\n",
    "Write a test function that implements this linear seperability test. Apply this test to your data $(X,T)$ from Task 1 and your manually selected line $\\vec w$ from Task 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separability_test(X, T, w):\n",
    "  ...\n",
    "\n",
    "# Test 1: check that the weights are separating the data\n",
    "if separability_test(X, T, w_manual):\n",
    "  print(\"The data is separated by the manually selected line\")\n",
    "else:\n",
    "  print(\"The anually selected line does not separate the data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Perceptron\n",
    "------------------\n",
    "\n",
    "The perceptron is defined as the line $a = f_{\\vec w}(\\vec x)$ that is thresholded using the sign function $\\mathrm{sign}(a) = \\begin{cases} +1 &\\text{if } a \\geq 0\\\\ -1 & \\text{otherwise.}\\end{cases}$\n",
    "Implement a function that computes and returns the perceptron for a given data point $\\vec x$ and line parameters $\\vec w$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(x, w):\n",
    "  ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptron learning rule is defined as follows.\n",
    "First, the weights $\\vec w = (w_0, w_1, w_2)^T$ is initialized randomly.\n",
    "Then, for each sample $(x,t)$ of the dataset we check if the sample is correcly classified as $H(f_{\\vec w}(\\vec x)) t > 0$.\n",
    "If the sample is classified incorrectly, the weights are adapted: $w_0 = w_0 + t$, $w_1 = w_1 + tx_1$, $w_2 = w_2 + tx_2$.\n",
    "This step is repeated until all samples are classified correcly.\n",
    "\n",
    "\n",
    "Task 4: Perceptron Learning Implementation\n",
    "------------------------------------------\n",
    "Implement a funtion that performs perceptron learning for a given dataset $(X,T)$ and a given initial weight vector $\\vec w$.\n",
    "The final weight vector $\\vec w^*$ shall be returned from that function.\n",
    "Define a proper stopping criterion for the iteration.\n",
    "Consider in your implementation error cases that could arise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_learning(X, T, w):\n",
    "  # first, make a copy of your weights\n",
    "  w_star = ...\n",
    "\n",
    "  # then, iterate over the data and perform perceptron learning\n",
    "  ...\n",
    "  \n",
    "  # finally, return the optimal weights\n",
    "  return w_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2: Sanity Check\n",
    "--------------------\n",
    "Call the perceptron learning function with the data from task 1 and the manual line from task 2. What is the expected outcome? Test if this is the actual outcome of the perceptron learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_star = perceptron_learning(X, T, w_manual)\n",
    "\n",
    "# check if the output is as expected\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Task 5: Weight Initialization\n",
    "-----------------------------\n",
    "\n",
    "Implement a function that generates and returns randomly initialized weights $\\vec w \\in [-1,1]^3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_weights(min = -1, max = 1):\n",
    "  ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Perceptron Learning Execution\n",
    "-------------------------------------\n",
    "Call the perceptron learning function with the data from task 1 and the randomly generated initial weight vector from task 5.\n",
    "Store the resulting weight vector $\\vec w^*$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random weights\n",
    "w_initial = random_weights()\n",
    "\n",
    "# perform perceptron learning\n",
    "w_star = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 3: Result Validation\n",
    "-------------------------\n",
    "Verify that $\\vec w^*$ separates the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify that we have learned to separate the data\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Visualization\n",
    "---------------------\n",
    "\n",
    "For visualization, we want to jointly plot the positive and negative data from Task 1, together with the descision boundaries of the weight vectors obtained in Tasks 2 and 6. An example can be found below:\n",
    "\n",
    "![Sample Solution](./DL-Solution01.png)\n",
    "\n",
    "First, we need to plot the data points such that positive data are plotted with green dots, and negative data with red dots.\n",
    "\n",
    "Then, we need to compute the line parameters. For this purpose, we define the separating line in cartesian coordinates $f_{\\vec w}(\\vec x) = 0$ and solve it to the paramteric form $x_2 = \\beta x_1 + \\gamma$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_parameters(w):\n",
    "  # compute parametric line parameters from cartesian coordinates\n",
    "  beta = ...\n",
    "  gamma = ...\n",
    "  return beta, gamma\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# plot the positive data points\n",
    "pyplot.plot(..., ..., \"g.\", label=\"positive data\")\n",
    "# plot the negative data points\n",
    "pyplot.plot(..., ..., \"r.\", label=\"negative data\")\n",
    "\n",
    "# define positions where to evaluate the line:\n",
    "x1 = ...\n",
    "\n",
    "# compute line parameters for manual line\n",
    "beta, gamma = line_parameters(w_manual)\n",
    "# now, compute the values according to our parametric form:\n",
    "x2 = beta * x1 + gamma\n",
    "# plot lines (might need to call this function twice for the two lines)\n",
    "pyplot.plot(x1, x2, \"m-\", label=\"manual line\")\n",
    "\n",
    "# compute line parameters for optimized line\n",
    "beta, gamma = line_parameters(w_star)\n",
    "# now, compute the values according to our parametric form:\n",
    "x2 = beta * x1 + gamma\n",
    "# plot lines (might need to call this function twice for the two lines)\n",
    "pyplot.plot(x1, x2, \"b-\", label=\"optimized line\")\n",
    "\n",
    "# make the plot more beautiful\n",
    "...\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
