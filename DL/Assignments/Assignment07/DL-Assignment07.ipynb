{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 7: Transfer Learning\n",
    "===============================\n",
    "\n",
    "\n",
    "Microsoft Forms Document: https://forms.office.com/r/MvPiCwh6jR\n",
    "\n",
    "\n",
    "Here, we use parts of the Fruits and Vegetables dataset that can be downloaded from Kaggle: https://www.kaggle.com/datasets/kritikseth/fruit-and-vegetable-image-recognition\n",
    "\n",
    "For this small example, I have subselected some images, which are available here: https://seafile.ifi.uzh.ch/f/72e1d9c4ef20420eb1d9/?dl=1\n",
    "\n",
    "First, we need to download and extract all our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dataset_zip_file = \"fruits.zip\"\n",
    "if not os.path.exists(dataset_zip_file):\n",
    "  import urllib.request\n",
    "  urllib.request.urlretrieve(\"https://seafile.ifi.uzh.ch/f/72e1d9c4ef20420eb1d9/?dl=1\", dataset_zip_file)\n",
    "  print (\"Downloaded datafile\", dataset_zip_file)\n",
    "  import zipfile\n",
    "  zipfile.ZipFile(dataset_zip_file).extractall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 1: Data Transformation\n",
    "---------------------------\n",
    "\n",
    "We need to instantiate a proper `torchvision.transform` instance to create the same input structure as used for training our network.\n",
    "We need to combine 4 transforms, which can be compiled from the PyTorch website: https://pytorch.org/vision/stable/models.html\n",
    "\n",
    "1. We need to resize the image such that the shorter side has size 256.\n",
    "2. We need to take the center crop of size $224\\times224$ from the image.\n",
    "3. We need to convert the image into a tensor (including pixel values scaling)\n",
    "4. We need to normalize the pixel values with mean $(0.485, 0.456, 0.406)$ and standard deviation $(0.229, 0.224, 0.225)\n",
    "\n",
    "Since we will use networks pre-trained on ImageNet, we need to perform the exact same transform as used for ImageNet testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "imagenet_transform = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Dataset Loading\n",
    "-----------------------\n",
    "\n",
    "We here use the `torchvision.datasets.ImageFolder` dataset interface for processing images. \n",
    "You can use its documented `is_valid_file` parameter to distinguish between training and test set.\n",
    "The training files are all called `gallery.jpg` while test files are called `probe.jpg`.\n",
    "\n",
    "Create two datasets, one for the training set, one for the test set. Use the transform defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.ImageFolder(\n",
    "  root = \"fruits\",\n",
    "  ...\n",
    ")\n",
    "\n",
    "testset = torchvision.datasets.ImageFolder(\n",
    "  root = \"fruits\",\n",
    "  ...\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 1: Data Size and Types\n",
    "---------------------------\n",
    "\n",
    "Check that all datasets contain the same number of images as classes.\n",
    "Check that all input images are `torch.tensor`s of size $3\\times224\\times224$ and of type `torch.float`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(trainset) == len(testset))\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Pre-trained Network\n",
    "---------------------------\n",
    "\n",
    "Instantiate a pre-trained network of type ResNet-18. \n",
    "Modify the network such that we extract the deep features from before the last fully-connected layer of the network.\n",
    "For your reference, the implementation of the `forward` function of ResNet networks (including ResNet-18) can be found here: https://github.com/pytorch/vision/blob/main/torchvision/models/resnet.py#L264\n",
    "\n",
    "You can also check if other networks perform better, especially deeper ResNet topologies.\n",
    "Be aware that our strategy to remove the last fully-connected layer might not work in other network topologies, only in residual networks.\n",
    "\n",
    "Please Note: while we modify the `forward` function, we will still use the `__call__` function to extract our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate pre-trained resnet 18 network\n",
    "network = ...\n",
    "\n",
    "# make sure that deep features can be etxracted from the network\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Extract Features\n",
    "------------------------\n",
    "\n",
    "Implement a function that extracts all features for a given dataset.\n",
    "Store the results in a dictionary: `target : feature`.\n",
    "Extract the features for the training and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(network, dataset):\n",
    "  features = {}\n",
    "  ...\n",
    "  return features\n",
    "\n",
    "train_features = ...\n",
    "test_features = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test 2: Check your Features\n",
    "---------------------------\n",
    "\n",
    "Check that all your features are of dimension 512 and of datatype `torch.float` (larger ResNet topologies might have 2048-dimensional features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check features\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Similarity Computation\n",
    "------------------------------\n",
    "\n",
    "Iterate over all samples in the test set.\n",
    "Compute the cosine similarities to all samples in the training set.\n",
    "Store the similarity values in a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "O = ...\n",
    "similarities = torch.empty((O, O))\n",
    "\n",
    "# compute similarities\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Plot Similarity Values\n",
    "------------------------------\n",
    "\n",
    "Plot the similarity matrix as an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# plot similarities\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Classification Accuracy\n",
    "-------------------------------\n",
    "\n",
    "Compute the classification accuracy by checking if the class of highest similarity for a test sample is the correct class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy for our small test set\n",
    "accuracy = ...\n",
    "print(\"Accuracy is\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Find Misclassified Images and Classes\n",
    "----------------------------------------------\n",
    "\n",
    "Find the test samples that are incorrectly classified. \n",
    "Get the class names (not only indexes) and write the names of the test sample class as well as the class that it was classified as.\n",
    "\n",
    "What are the two most dissimilar classes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classnames = ...\n",
    "\n",
    "# find all misclassified test images and print their real and predicted class name\n",
    "...\n",
    "\n",
    "# find the pair of most dissimilar training and test class and print their names\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2dd53f8ad749bca69f7250ce75eb4f0def59db5cf79075a9716322ffc58e8a2e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
