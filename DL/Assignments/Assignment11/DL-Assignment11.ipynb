{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 11: Adversarial Training\n",
    "===================================\n",
    "\n",
    "\n",
    "Microsoft Forms Document: https://forms.office.com/r/e3n9gYXsL5\n",
    "\n",
    "In this assignment we will show that adversarial training provides stability against adversarial attacks for the MNIST dataset.\n",
    "We will compare three different types of training procedures:\n",
    "\n",
    "1. Train with only the original samples\n",
    "2. Train with original samples and added random noise\n",
    "3. Train with original samples and adversarial samples\n",
    "\n",
    "Note that the results of this experiment might not translate well to other datasets.\n",
    "\n",
    "Task 1: Dataset\n",
    "---------------\n",
    "\n",
    "We will make use of the default implementations of the MNIST dataset.\n",
    "As usual, we will need the training and validation set splits of MNIST, including data loaders.\n",
    "Select appropriate batch sizes for training and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# training set and data loader\n",
    "train_loader = ...\n",
    "\n",
    "# validation set and data loader\n",
    "validation_loader = ...\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 2: Classification Network\n",
    "------------------------------\n",
    "We use the same small-scale network as we have done in assignment 8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network (torch.nn.Module):\n",
    "  def __init__(self, Q1, Q2, K, O):\n",
    "    # call base class constrcutor\n",
    "    super(Network,self).__init__()\n",
    "    ...\n",
    "  \n",
    "  def forward(self,x):\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 3: Fast Gradient Sign\n",
    "--------------------------\n",
    "\n",
    "For adversarial training, we need to implement a function to generate an adversarial sample for a given input.\n",
    "Here, we are implementing the Fast Gradient Sign method, which modifies the given input by adding a scaled version of the sign of the gradient:\n",
    "\n",
    "$$\\mathbf X_{\\mathrm{FGS}} = \\mathbf X + \\alpha\\,\\mathrm{sign}(\\nabla_{\\mathbf X} \\mathcal J)$$\n",
    "\n",
    "Finally, the result needs to be clamped to be in range $[0,1]$.\n",
    "\n",
    "Note that this function will be used with batches of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FGS(x, t, network, loss, alpha=0.3):\n",
    "  # tell autograd that we need the gradient for the input\n",
    "  ...\n",
    "  # forward input\n",
    "  z = ...\n",
    "  # compute loss and gradient\n",
    "  J = ...\n",
    "\n",
    "  # get the gradient\n",
    "  gradient = ...\n",
    "  # create FGS adversarial sample\n",
    "  adversarial_sample = ...\n",
    "  \n",
    "  return adversarial_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 4: Random Noise\n",
    "--------------------\n",
    "For comparison, we want a function that produces noise similar to FGS, which we add to the image:\n",
    "\n",
    "$$\\mathbf X_{\\mathrm{noise}} = \\mathbf X + \\alpha \\{-1,1\\} ^{D\\times E}$$\n",
    "\n",
    "Here, $-1$ and $1$ are sampled with the same probability, and independently for each pixel.\n",
    "\n",
    "Again, we clamp the results to be in range $[0,1]$.\n",
    "\n",
    "Note that this function will also be used with batches of samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noise(x, alpha=0.3, **kwargs):\n",
    "  # generate noise \n",
    "  N = ...\n",
    "  # Add noise and clamp\n",
    "  noisy_sample = ...\n",
    "\n",
    "  return noisy_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 5: Training Loop\n",
    "---------------------\n",
    "\n",
    "Implement a training and validation loop that possibly includes training with adversarial or with noise samples.\n",
    "This loop iterates over all training batches once, i.e., we implement one epoch of training here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(network, loss, optimizer, add_additional_samples = None, alpha=0.3):\n",
    "  for x,t in train_loader:\n",
    "    # compute output for current batch\n",
    "    z = ...\n",
    "    # compute loss\n",
    "    J = ...\n",
    "    # compute gradient\n",
    "    ...\n",
    "\n",
    "    if add_additional_samples is not None:\n",
    "      # compute modified samples for batch\n",
    "      if add_additional_samples == \"FGS\":\n",
    "        # create FGS adversarial samples\n",
    "        x_hat = ...\n",
    "      else:\n",
    "        # create noisy samples\n",
    "        x_hat = ...\n",
    "\n",
    "      # compute output for modified samples\n",
    "      z_hat = ...\n",
    "      # compute loss on modified samples\n",
    "      J = ...\n",
    "      # compute gradient\n",
    "      ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 6: Validation Loop\n",
    "-----------------------\n",
    "\n",
    "We need to compute both the classification accuracy and the adversarial stability for the validation set.\n",
    "For each batch, first we select the correctly classified images.\n",
    "For these, we generate FGS adversarial samples.\n",
    "Finally, we test whether these adversarial samples are classified as the original classes.\n",
    "\n",
    "Compute classification accuracy and adversarial accuracy on the whole test set.\n",
    "Think about how to normalize the adversarial accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_loop(network, loss, alpha=0.3):\n",
    "  total, correct_clean_count, correct_adversarial_count = 0,0,0\n",
    "\n",
    "  # iterate over validation set samples\n",
    "  for x,t in validation_loader:\n",
    "    with torch.no_grad():\n",
    "      # classify original samples\n",
    "      z = ...\n",
    "\n",
    "      # compute classification accuracy on original samples\n",
    "      correct_clean_count += ...\n",
    "\n",
    "    # select the correctly classified samples\n",
    "    ...\n",
    "    \n",
    "    # create adversarial samples using FGS\n",
    "    x_FGS = ...\n",
    "\n",
    "    # check how many are correctly classified\n",
    "    with torch.no_grad():\n",
    "      # classify adversarial samples\n",
    "      z_FGS = ...\n",
    "\n",
    "      # compute classification accuracy on adversarial samples\n",
    "      correct_adversarial_count += ...\n",
    "\n",
    "  # compute clean and adversarial accuracy and return them\n",
    "  clean_accuracy = ...\n",
    "  adversarial_accuracy = ...\n",
    "  return clean_accuracy, adversarial_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 7: Training of Three Networks\n",
    "----------------------------------\n",
    "\n",
    "Instantiate three different but identical networks.\n",
    "Instantiate according optimizers that train these networks.\n",
    "Train these networks for 10 epochs.\n",
    "The first network will be trained on clean samples only.\n",
    "The second network will be trained using adversarial samples.\n",
    "The third network will be trained with noise samples.\n",
    "\n",
    "Evaluate all three networks on the validation set, and record clean and adversarial classification accuracies.\n",
    "\n",
    "Note that the training time is extended as compared to a normal training since the creation of adversarial samples requires time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define one network for each training procedure\n",
    "networks = ...\n",
    "# define optimizer\n",
    "optimizer = ...\n",
    "\n",
    "# define loss function\n",
    "loss = ...\n",
    "\n",
    "# store accuracies on clean and adversarial samples for the three cases\n",
    "clean_accuracies = ...\n",
    "adversarial_accuracies = ...\n",
    "\n",
    "\n",
    "# iterate over 10 epochs (or more)\n",
    "for epoch in range(10):\n",
    "  # perform training loop\n",
    "  ...\n",
    "\n",
    "  # compute and store validation set accuracies\n",
    "  ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task 8: Plotting of Accuracies\n",
    "------------------------------\n",
    "\n",
    "Plot the different clean accuracies and adversarial accuracies over the training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.figure(figsize=(6,6))\n",
    "\n",
    "# plot clean accuracies\n",
    "pyplot.subplot(211)\n",
    "...\n",
    "\n",
    "# plot adversarial accuracies\n",
    "pyplot.subplot(212)\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a29cabff5744fce69e08a959ab87b9e77a9f67b498d08783caa8c3bb16f23a00"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('DL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
