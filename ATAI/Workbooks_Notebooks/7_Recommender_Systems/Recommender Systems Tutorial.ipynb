{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender Systems Tutorial\n",
    "\n",
    "This notebook will give you a short overview on how to implement different recommender systems approaches. We will start with implementing a basic `k nearest neighbors`(KNN) approach from scratch and will then continue to implement a movie recommender based on `sklearn`'s nearest neighbor method and finally we will compare two factorization approaches using an out-of-the-box recommendation framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in this tutorial, we will use a library called Surprise. This can be installed via pip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in /opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages (1.1.3)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages (from scikit-surprise) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages (from scikit-surprise) (1.21.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/Caskroom/miniforge/base/envs/conda-m1/lib/python3.8/site-packages (from scikit-surprise) (1.7.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the entire tutorial, we will use `numpy` and `pandas` as well as some `scipy` and `sklearn` functions. If you haven't installed these yet, now might be the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neighborhood-Based Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the tutorial with an illustrative example matrix that consists four users and 5 items. This is the same matrix that was used in the slide to this lecture.\n",
    "\n",
    "<img src=\"images/explicit-matrix.png\" width=400 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_matrix = np.array(\n",
    "    [\n",
    "        [5, 1, 0, 2, 2],\n",
    "        [1, 5, 2, 5, 5],\n",
    "        [2, 0, 3, 5, 4],\n",
    "        [4, 3, 5, 3, 0]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to predict how John would rate _Die Hard_. First, we need to find the users that are closest to John. There are multiple similarity or distance functions that can be applied. In this case, we will use the **cosine similarity**. We treat each user's rating behavior as a vector and compare them with each other. The result will be a number between 0 and 1, with 1 being two identical vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(xu, xv):\n",
    "    return np.dot(xu, xv)/(np.linalg.norm(xu)*np.linalg.norm(xv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute the similarity of John and Lucy (rows 0 and 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5752237416355278"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity(example_matrix[0, :], example_matrix[1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find John's the nearest neighbors, we need to compute the similarity for all users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.5752237416355278, 0.6534640392130712, 0.6474892069992044]\n"
     ]
    }
   ],
   "source": [
    "cosine_similarities = [cosine_similarity(example_matrix[0, :], example_matrix[i, :]) \n",
    "                       for i in range(example_matrix.shape[0])]\n",
    "print(cosine_similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that using the Cosine Similarity function, John's rating profile is most similar to Eric and Diane with not much of a difference between these two. Let's see if this observation is the same when we use a different distance measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Euclidean Distances [0.0, 7.3484692283495345, 5.656854249492381, 5.916079783099616]\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "euclidean_distances = [distance.euclidean(example_matrix[0, :], example_matrix[i, :]) \n",
    "                       for i in range(example_matrix.shape[0])]\n",
    "print('Euclidean Distances', euclidean_distances)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can predict John's rating for Die Hard based on his two nearest neighbors, Eric and Diane. Given the similarity of the vector distance, we apply a relatively small weight advantage towards the closest neighbor to John."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating = (0.6 * example_matrix[2, 2] + 0.4 * example_matrix[3, 2]) / (0.6 + 0.4)\n",
    "rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, there are a plethora of ready-to-use implementations for different recommendation methods available, so we don't have to implement everything from scratch. Let's use a bigger data set and use the KNN algorithm that sklearn provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN with Movielens and Sklearn\n",
    "\n",
    "The Movielens 100k data set consists of roughly 100,000 ratings of 9000 movies by 600 users. You can download this and other movie rating data sets on the [grouplens website](https://grouplens.org/datasets/movielens/latest/). I provided the two files that we will be working with in the `data` folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Movielens\n",
    "\n",
    "At first, we will load the `ratings.csv` file. We don't need the `timestamp` column which is why we will drop it right away."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       1        3     4.0\n",
       "2       1        6     4.0\n",
       "3       1       47     5.0\n",
       "4       1       50     5.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_ratings = pd.read_csv('data/ratings.csv', usecols=['userId', 'movieId', 'rating'])\n",
    "ml_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing\n",
    "At first, we need to transform the data frame into a rating matrix as seen in our toy example above. We will use an item-based recommendation approach, which is why we set the index to 'movieId' and the columns to 'userId'. Everytime a user has not rated a movie, we would get NaN. In order to feed the data into a KNN algorithm, we need to fill the NaNs with a numerical value, 0 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId   1    2    3    4    5    6    7    8    9    10   ...  601  602  603  \\\n",
       "movieId                                                    ...                  \n",
       "1        4.0  0.0  0.0  0.0  4.0  0.0  4.5  0.0  0.0  0.0  ...  4.0  0.0  4.0   \n",
       "2        0.0  0.0  0.0  0.0  0.0  4.0  0.0  4.0  0.0  0.0  ...  0.0  4.0  0.0   \n",
       "3        4.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4        0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5        0.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "userId   604  605  606  607  608  609  610  \n",
       "movieId                                     \n",
       "1        3.0  4.0  2.5  4.0  2.5  3.0  5.0  \n",
       "2        5.0  3.5  0.0  0.0  2.0  0.0  0.0  \n",
       "3        0.0  0.0  0.0  0.0  2.0  0.0  0.0  \n",
       "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5        3.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 610 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_matrix = ml_ratings.pivot(index='movieId', columns='userId', values='rating').fillna(0)\n",
    "ml_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see at first glance that the majority of the values in this matrix are 'unknowns'. Scipy offers an efficient way to work with such sparse matrices by compressing them to a csr (compressed sparse row format) matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "ml_csr = csr_matrix(ml_matrix.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the rating data, we also want to include the titles of the movies to be able to manually inspect the nearest neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title\n",
       "0        1                    Toy Story (1995)\n",
       "1        2                      Jumanji (1995)\n",
       "2        3             Grumpier Old Men (1995)\n",
       "3        4            Waiting to Exhale (1995)\n",
       "4        5  Father of the Bride Part II (1995)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df = pd.read_csv('data/movies.csv', usecols=['movieId', 'title'])\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the KNN model by setting the distance measure to cosine similarity and the algorithm to brute-force search. We hold out the first two movies, Toy Story and Jumanji as we want to find the most similar movies to these two later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_neighbors=17)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NearestNeighbors</label><div class=\"sk-toggleable__content\"><pre>NearestNeighbors(algorithm=&#x27;brute&#x27;, metric=&#x27;cosine&#x27;, n_neighbors=17)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_neighbors=17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=17)\n",
    "knn.fit(ml_csr[2:, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can select one movie and check which movies are the closest neighbors according to the user ratings. The `kneighbors` method takes a movie vector and returns a tuple with two arrays both of shape (1, number of neighbors). The first array is the similarity value, the second the row-indices of the 5 nearest neighbors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find the nearest neighbors for Toy Story, which is the first movie in our matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance, indices = knn.kneighbors(ml_csr[0], n_neighbors=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.42739874, 0.4343632 , 0.43573831, 0.44261183, 0.45290409,\n",
       "        0.45885465, 0.4589107 , 0.46108723, 0.46583124, 0.46961865,\n",
       "        0.4720232 , 0.47214083, 0.47967548, 0.48196726, 0.48581831,\n",
       "        0.48775438, 0.49068283, 0.49140738, 0.49145545, 0.49480359]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2351,  416,  613,  222,  312,  320,  908,  544,  961,  966, 3187,\n",
       "         504,  121,  255,  895,  813, 1180,   29,  275,   30]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what movies these indices correspond to. We first need to split off these movies from the `movie_df` and reset the data frame index before matching them by index. Otherwise the movie names will be off by two rows. Make sure that you only execute this cell once, otherwise it will keep removing the first two rows with every execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieId                               title\n",
       "0        3             Grumpier Old Men (1995)\n",
       "1        4            Waiting to Exhale (1995)\n",
       "2        5  Father of the Bride Part II (1995)\n",
       "3        6                         Heat (1995)\n",
       "4        7                      Sabrina (1995)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_df = movie_df.drop(index=[0, 1]).reset_index(drop=True)\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the 10 nearest neighbors to Toy Story:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2351                                 'night Mother (1986)\n",
      "416                                  Jurassic Park (1993)\n",
      "613                  Independence Day (a.k.a. ID4) (1996)\n",
      "222             Star Wars: Episode IV - A New Hope (1977)\n",
      "312                                   Forrest Gump (1994)\n",
      "320                                 Lion King, The (1994)\n",
      "908     Once Upon a Time in the West (C'era una volta ...\n",
      "544                            Mission: Impossible (1996)\n",
      "961                                           Diva (1981)\n",
      "966                           Arsenic and Old Lace (1944)\n",
      "3187            Rififi (Du rififi chez les hommes) (1955)\n",
      "504                                        Aladdin (1992)\n",
      "121                                      Apollo 13 (1995)\n",
      "255                                   Pulp Fiction (1994)\n",
      "895                 Cheech and Chong's Up in Smoke (1978)\n",
      "813            Willy Wonka & the Chocolate Factory (1971)\n",
      "1180                                          Fall (1997)\n",
      "29              Twelve Monkeys (a.k.a. 12 Monkeys) (1995)\n",
      "275                      Shawshank Redemption, The (1994)\n",
      "30                                            Babe (1995)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "for i in indices:\n",
    "    print(movie_df['title'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can repeat the same thing with Jumanji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320                                Lion King, The (1994)\n",
      "434                                Mrs. Doubtfire (1993)\n",
      "323                                     Mask, The (1994)\n",
      "416                                 Jurassic Park (1993)\n",
      "502                                    Home Alone (1990)\n",
      "481               Nightmare Before Christmas, The (1993)\n",
      "504                                       Aladdin (1992)\n",
      "510                          Beauty and the Beast (1991)\n",
      "16                 Ace Ventura: When Nature Calls (1995)\n",
      "274                             Santa Clause, The (1994)\n",
      "129                                        Casper (1995)\n",
      "273                                      Stargate (1994)\n",
      "174                                    Waterworld (1995)\n",
      "335                                     True Lies (1994)\n",
      "332                                         Speed (1994)\n",
      "503                                         Ghost (1990)\n",
      "215    Interview with the Vampire: The Vampire Chroni...\n",
      "136                    Die Hard: With a Vengeance (1995)\n",
      "613                 Independence Day (a.k.a. ID4) (1996)\n",
      "507                                        Batman (1989)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "similarity, indices = knn.kneighbors(ml_csr[1], n_neighbors=20)\n",
    "for i in indices:\n",
    "    print(movie_df['title'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at both lists, you can find similar movies based on a rating matrix. However, there might be better approaches than finding similar movies based on the rating behavior of the users.\n",
    "Additionally, manually inspecting the movie list is not exactly an objective evaluation method. Let's have a closer look at both in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factorization Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While it is also possible to implement a factorization approach using sklearn, be using the [Surprise](http://surpriselib.com/) library for this part of the tutorial to show you an out-of-the-box approach. Surprise is one of many frameworks that provide a selection of recommendation methods for explicit feedback data in a ready-to-use manner. It was heavily inspired by sklearn and uses a similar syntax and provides builtin datasets and evaluation metrics.\n",
    "\n",
    "We will compare the performance of 2 factorization methods, Singular Value Decomposition (SVD) which became popular when it lead to winning the third place in the Netflix competition, and the similar Non-Negative Matrix Factorization (NMF). You can check out the maths behind both approaches in the documentation ([Link to SVD](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.SVD), [Link to NMF](https://surprise.readthedocs.io/en/stable/matrix_factorization.html#surprise.prediction_algorithms.matrix_factorization.NMF))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import the functions that we will need for this comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, NMF\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection.split import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprise uses their own data format. They provide functions to load external data from a file or a pandas data frame, but lucky for us, the movielens 100k data is one of their builtin data set. Let's load it and split off 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "\n",
    "trainset, testset = train_test_split(data, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to worry about any data transformation as Surprise takes care of this. This is why we can initialize and fit the data to the SVD algorithm right away. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x1689395e0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd_algo = SVD(random_state = 42)\n",
    "svd_algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `test` function will create the predictions for our test set. It returns a list with a user ID, item ID, the actual rating, and the estimated rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='907', iid='143', r_ui=5.0, est=4.611536250297749, details={'was_impossible': False}),\n",
       " Prediction(uid='371', iid='210', r_ui=4.0, est=4.37114223755087, details={'was_impossible': False}),\n",
       " Prediction(uid='218', iid='42', r_ui=4.0, est=3.7387439108043528, details={'was_impossible': False}),\n",
       " Prediction(uid='829', iid='170', r_ui=4.0, est=3.8854605526859616, details={'was_impossible': False}),\n",
       " Prediction(uid='733', iid='277', r_ui=1.0, est=2.951243324162181, details={'was_impossible': False}),\n",
       " Prediction(uid='363', iid='1512', r_ui=1.0, est=3.1175626582710105, details={'was_impossible': False}),\n",
       " Prediction(uid='193', iid='487', r_ui=5.0, est=3.584277708279981, details={'was_impossible': False}),\n",
       " Prediction(uid='808', iid='313', r_ui=5.0, est=4.694317679756497, details={'was_impossible': False}),\n",
       " Prediction(uid='557', iid='682', r_ui=2.0, est=3.1886298403272635, details={'was_impossible': False}),\n",
       " Prediction(uid='774', iid='196', r_ui=3.0, est=2.438638505544496, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_svd = svd_algo.test(testset)\n",
    "predictions_svd[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From manual inspection, you can see that a couple of predictions are a bit off while others are very close to the ground truth. Let's put a number to the predictive performance. As we are dealing with explicit data, we can use the `Root Mean Squared Error` (RMSE) to determine the predictive performance. With this metric, a lower value indicates a higher accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.935171451026933"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions_svd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at another Factorization method, non-negative matrix factorization (NMF). Again, we initialize the model with the default parameters and fit it on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.NMF at 0x168939670>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_algo = NMF(random_state = 42)\n",
    "nmf_algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='907', iid='143', r_ui=5.0, est=4.8146792545930674, details={'was_impossible': False}),\n",
       " Prediction(uid='371', iid='210', r_ui=4.0, est=4.19512578582791, details={'was_impossible': False}),\n",
       " Prediction(uid='218', iid='42', r_ui=4.0, est=3.525580274112197, details={'was_impossible': False}),\n",
       " Prediction(uid='829', iid='170', r_ui=4.0, est=4.131742088580094, details={'was_impossible': False}),\n",
       " Prediction(uid='733', iid='277', r_ui=1.0, est=3.709656181355705, details={'was_impossible': False}),\n",
       " Prediction(uid='363', iid='1512', r_ui=1.0, est=4.118810905573852, details={'was_impossible': False}),\n",
       " Prediction(uid='193', iid='487', r_ui=5.0, est=3.9782946152950114, details={'was_impossible': False}),\n",
       " Prediction(uid='808', iid='313', r_ui=5.0, est=4.94266576388802, details={'was_impossible': False}),\n",
       " Prediction(uid='557', iid='682', r_ui=2.0, est=2.6266692176433857, details={'was_impossible': False}),\n",
       " Prediction(uid='774', iid='196', r_ui=3.0, est=2.2686929898676316, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_nmf = nmf_algo.test(testset)\n",
    "predictions_nmf[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictions look very similar to the SVD results. The majority of the estimated ratings are close to the ground truth, but in the middle of the list, the values are pretty off. Let's see if the RSME will confirm this impression that the performance is very similar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9594077989819741"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions_nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both results only differ by 0.02 and there is most likely room for improvement in both cases by tuning the parameters. However, even with default parameters, the results are not too bad. Let's inspect the actual top-n recommendations for the users to see if this small difference in accuracy has an impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `get_top_n` function was taken from an [example script](https://surprise.readthedocs.io/en/stable/FAQ.html#top-n-recommendations-py) provided by the Surprise library. It iterates through the predictions list and assigns the item IDs and the estimated ratings to the corresponding user ID in a dictionary. The item IDs are then sorted by estimated rating and the resulting list is cut off at `n`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we apply this function to both prediction list, we will only get movie IDs in return. To get a better intuition, we match these IDs back with the titles in the `movie_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 907\n",
      "movie recommendations: Juror, The (1996), Johnny Mnemonic (1995), Courage Under Fire (1996), Flirting With Disaster (1996), Leaving Las Vegas (1995), Net, The (1995), Judge Dredd (1995), Brothers McMullen, The (1995), \n",
      "\n",
      "user: 371\n",
      "movie recommendations: Wild Bill (1995), Hate (Haine, La) (1995), Nine Months (1995), Forget Paris (1995), Kids (1995), Georgia (1995), Carlito's Way (1993), \n",
      "\n",
      "user: 218\n",
      "movie recommendations: White Man's Burden (1995), Dracula: Dead and Loving It (1995), Dead Presidents (1995), Devil in a Blue Dress (1995), Striptease (1996), Seven (a.k.a. Se7en) (1995), True Crime (1996), \n",
      "\n",
      "user: 829\n",
      "movie recommendations: 8 Seconds (1994), Safe (1995), Hackers (1995), Burnt by the Sun (Utomlyonnye solntsem) (1994), Strange Days (1995), From Dusk Till Dawn (1996), Anne Frank Remembered (1995), Girl 6 (1996), \n",
      "\n",
      "user: 733\n",
      "movie recommendations: Nixon (1995), Remains of the Day, The (1993), Sunset Blvd. (a.k.a. Sunset Boulevard) (1950), Escape from New York (1981), Balto (1995), Miracle on 34th Street (1994), Striptease (1996), Hudsucker Proxy, The (1994), \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVD Recommendations\n",
    "top_n = get_top_n(predictions_svd, n=10)\n",
    "for uid, user_ratings in list(top_n.items())[:5]:\n",
    "    print('user:', uid)\n",
    "    print('movie recommendations: ', end='')\n",
    "    for iid, _ in user_ratings:\n",
    "        movie = movie_df.loc[movie_df['movieId'] == int(iid)]['title']\n",
    "        if not movie.empty:\n",
    "            print(movie.values[0], end=', ')\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 907\n",
      "movie recommendations: Judge Dredd (1995), Larger Than Life (1996), Juror, The (1996), Johnny Mnemonic (1995), Courage Under Fire (1996), Net, The (1995), Flirting With Disaster (1996), Santa Clause, The (1994), \n",
      "\n",
      "user: 371\n",
      "movie recommendations: Kids (1995), Wild Bill (1995), Hate (Haine, La) (1995), Forget Paris (1995), Georgia (1995), Nine Months (1995), Carlito's Way (1993), \n",
      "\n",
      "user: 218\n",
      "movie recommendations: Dracula: Dead and Loving It (1995), White Man's Burden (1995), Devil in a Blue Dress (1995), Dead Presidents (1995), Seven (a.k.a. Se7en) (1995), Striptease (1996), True Crime (1996), \n",
      "\n",
      "user: 829\n",
      "movie recommendations: 8 Seconds (1994), Hackers (1995), Safe (1995), Pie in the Sky (1996), Strange Days (1995), Burnt by the Sun (Utomlyonnye solntsem) (1994), Girl 6 (1996), Circle of Friends (1995), Anne Frank Remembered (1995), \n",
      "\n",
      "user: 733\n",
      "movie recommendations: Nixon (1995), Miracle on 34th Street (1994), Remains of the Day, The (1993), Balto (1995), Escape from New York (1981), Sunset Blvd. (a.k.a. Sunset Boulevard) (1950), Old Man and the Sea, The (1958), Hudsucker Proxy, The (1994), Striptease (1996), \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NMF Recommendations\n",
    "top_n = get_top_n(predictions_nmf, n=10)\n",
    "for uid, user_ratings in list(top_n.items())[:5]:\n",
    "    print('user:', uid)\n",
    "    print('movie recommendations: ', end='')\n",
    "    for iid, _ in user_ratings:\n",
    "        movie = movie_df.loc[movie_df['movieId'] == int(iid)]['title']\n",
    "        if not movie.empty:\n",
    "            print(movie.values[0], end=', ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For better visibility, I copy/pasted the results of the first 3 users into this table:\n",
    "\n",
    "| UserId   | SVD                      | NMF                    |\n",
    "|:--------:|:-------------------------|:-----------------------|\n",
    "| 907      |Juror, The (1996)         |Judge Dredd (1995)      |\n",
    "|          |Johnny Mnemonic (1995)    |Larger Than Life (1996) |\n",
    "|          |Courage Under Fire (1996) | Juror, The (1996)      |\n",
    "|          |Flirting With Disaster (1996)| Johnny Mnemonic (1995)|\n",
    "|          |Leaving Las Vegas (1995)  | Courage Under Fire (1996)|\n",
    "|          |Net, The (1995)           | Net, The (1995)      |\n",
    "|          |Judge Dredd (1995)        | Flirting With Disaster (1996)      |\n",
    "|          |Brothers McMullen, The (1995)| Santa Clause, The (1994)   |\n",
    "| 371      |Wild Bill (1995)          |  Kids (1995)     |\n",
    "|          |Hate (Haine, La) (1995)   |  Wild Bill (1995)     |\n",
    "|          |Nine Months (1995)        |  Hate (Haine, La) (1995)     |\n",
    "|          |Forget Paris (1995)       |  Forget Paris (1995)     |\n",
    "|          |Kids (1995)               |  Georgia (1995)     |\n",
    "|          |Georgia (1995)            |  Nine Months (1995)     |\n",
    "|          |Carlito's Way (1993)      |   Carlito's Way (1993)    |\n",
    "| 218      |White Man's Burden (1995) |  Dracula: Dead and Loving It (1995) |\n",
    "|          |Dracula: Dead and Loving It (1995)| White Man's Burden (1995)          |\n",
    "|          |Dead Presidents (1995)    |    Devil in a Blue Dress (1995)          |\n",
    "|          |Devil in a Blue Dress (1995)|  Dead Presidents (1995)          |\n",
    "|          |Striptease (1996)         |    Seven (a.k.a. Se7en) (1995)          |\n",
    "|          |Seven (a.k.a. Se7en) (1995)|    Striptease (1996)         |\n",
    "|          |True Crime (1996)          |    True Crime (1996)         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table you can see that the order of the list differs slightly, but 80-100% of the movies overlap. From this small sample size, the difference in the RSME does not seem to have a big impact on the recommendations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, Surprise provides an easy to use approach to building a recommender system. If I need more control over what is happening, it is better to implement your recommendation system with sklearn, scipy and the likes as Surprise behaves like a black box."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ce2cff08cd15a34cfbbe13a586664ebd350757fd030a545d831779bd59aaad32"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
